<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>üçé SRE Journey</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> üõ∂ Introduction</a></li><li class="chapter-item expanded "><a href="becoming_sre.html"><strong aria-hidden="true">2.</strong> üìö Becoming SRE</a></li><li class="chapter-item expanded "><a href="k8s.html"><strong aria-hidden="true">3.</strong> ‚õµÔ∏è k8s</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ckad_prep.html"><strong aria-hidden="true">3.1.</strong> üìú CKAD prep</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ckad_prep_1.html"><strong aria-hidden="true">3.1.1.</strong> üêøÔ∏è k8s in a Nutshell</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ckad_prep_2.html"><strong aria-hidden="true">3.1.1.1.</strong> Object Management</a></li></ol></li><li class="chapter-item expanded "><a href="ckad_prep_first_mod.html"><strong aria-hidden="true">3.1.2.</strong> üêî Application Design and Build</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ckad_prep_3.html"><strong aria-hidden="true">3.1.2.1.</strong> Container Images</a></li><li class="chapter-item expanded "><a href="ckad_prep_4.html"><strong aria-hidden="true">3.1.2.2.</strong> Pods</a></li><li class="chapter-item expanded "><a href="ckad_prep_5.html"><strong aria-hidden="true">3.1.2.3.</strong> Jobs and CronJobs</a></li><li class="chapter-item expanded "><a href="ckad_prep_6.html"><strong aria-hidden="true">3.1.2.4.</strong> Container Storage</a></li><li class="chapter-item expanded "><a href="ckad_prep_7.html"><strong aria-hidden="true">3.1.2.5.</strong> Multi-Container Pods</a></li><li class="chapter-item expanded "><a href="ckad_prep_8.html"><strong aria-hidden="true">3.1.2.6.</strong> Labels and Annotations</a></li></ol></li><li class="chapter-item expanded "><a href="ckad_prep_second_mod.html"><strong aria-hidden="true">3.1.3.</strong> üê¶ Application Deployment</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ckad_prep_9.html"><strong aria-hidden="true">3.1.3.1.</strong> Deployments</a></li><li class="chapter-item expanded "><a href="ckad_prep_10.html"><strong aria-hidden="true">3.1.3.2.</strong> Helm</a></li></ol></li><li class="chapter-item expanded "><a href="ckad_prep_third_mod.html"><strong aria-hidden="true">3.1.4.</strong> üê§ Application Observability & Maintenance</a></li><li class="chapter-item expanded "><a href="ckad_focus.html"><strong aria-hidden="true">3.1.5.</strong> üî¨ Where to Focus</a></li></ol></li><li class="chapter-item expanded "><a href="k8s_up_and_running.html"><strong aria-hidden="true">3.2.</strong> üêã k8s up and running</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="k8s_up_and_running_1.html"><strong aria-hidden="true">3.2.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_2.html"><strong aria-hidden="true">3.2.2.</strong> Deploying a k8s cluster</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_3.html"><strong aria-hidden="true">3.2.3.</strong> Common kubectl commands</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_4.html"><strong aria-hidden="true">3.2.4.</strong> Pods</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_5.html"><strong aria-hidden="true">3.2.5.</strong> Labels</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_6.html"><strong aria-hidden="true">3.2.6.</strong> Services</a></li><li class="chapter-item expanded "><a href="k8s_up_and_running_13.html"><strong aria-hidden="true">3.2.7.</strong> ConfigMap and Secrets</a></li></ol></li><li class="chapter-item expanded "><a href="k8s_cheatsheet.html"><strong aria-hidden="true">3.3.</strong> üìù k8s cheatsheet</a></li><li class="chapter-item expanded "><a href="helm.html"><strong aria-hidden="true">3.4.</strong> ‚éà helm</a></li></ol></li><li class="chapter-item expanded "><a href="fluentd.html"><strong aria-hidden="true">4.</strong> ü¶ú Fluentd</a></li><li class="chapter-item expanded "><a href="elk_stack.html"><strong aria-hidden="true">5.</strong> üìà ELK Stack</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">üçé SRE Journey</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="-introduction"><a class="header" href="#-introduction">üõ∂ Introduction</a></h1>
<p>I will document my journey into the SRE world here, you will find notes from
books I am reading, as well as other stuff I find relevant throughout the
journey.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="becoming-sre"><a class="header" href="#becoming-sre">Becoming SRE</a></h1>
<blockquote>
<p>‚ö†Ô∏è These are notes taken from the book <a href="https://learning.oreilly.com/library/view/becoming-sre/9781492090540/"><em>Becoming SRE</em> by David N. Blank-Edelman
O'Reilly</a>.
It is an splendid book and no amount of notes I take will make it justice,
<strong>please go read it and just use this as a reference</strong>.</p>
</blockquote>
<h1 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h1>
<ul>
<li><a href="becoming_sre.html#introduction-to-sre">Introduction to SRE</a>
<ul>
<li><a href="becoming_sre.html#first-things-first">First things first</a>
<ul>
<li><a href="becoming_sre.html#sre-vs-devops">SRE vs Devops</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#sre-mindset">SRE Mindset</a>
<ul>
<li><a href="becoming_sre.html#keeping-focus-on-the-customer">Keeping Focus on the Customer</a></li>
<li><a href="becoming_sre.html#sres-relationship-with-failure">SRE‚Äôs Relationship with Failure</a></li>
<li><a href="becoming_sre.html#the-mindset-in-motion">The Mindset in Motion</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#culture">Culture</a>
<ul>
<li><a href="becoming_sre.html#new-hires">New hires</a></li>
<li><a href="becoming_sre.html#avoid">Avoid</a></li>
<li><a href="becoming_sre.html#cool-ideas-to-improve-culture">Cool Ideas to improve culture</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#sre-advocacy">SRE Advocacy</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#becoming-sre-for-the-individual">Becoming SRE for the Individual</a>
<ul>
<li><a href="becoming_sre.html#preparing-to-be-an-sre">Preparing to be an SRE</a>
<ul>
<li><a href="becoming_sre.html#do-i-need-to-know-how-to-code-yes">Do I need to know how to code? Yes</a></li>
<li><a href="becoming_sre.html#fundamentals">Fundamentals</a></li>
<li><a href="becoming_sre.html#other-nice-to-have">Other nice to have</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#getting-to-sre-from">Getting to SRE from‚Ä¶.</a>
<ul>
<li><a href="becoming_sre.html#from-devswe">From Dev/SWE</a></li>
<li><a href="becoming_sre.html#from-sysadmin">From Sysadmin</a></li>
<li><a href="becoming_sre.html#more-advice">More advice</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#hints-for-getting-hired-as-an-sre">Hints for Getting Hired as an SRE</a>
<ul>
<li><a href="becoming_sre.html#looking-closely-at-the-job-posting">Looking closely at the job posting</a></li>
<li><a href="becoming_sre.html#preparing-for-an-sre-interview-resources">Preparing for an SRE interview (Resources)</a></li>
<li><a href="becoming_sre.html#what-to-ask-at-the-sre-interview">What to ask at the SRE Interview</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#a-day-in-the-life-of-an-sre">A Day in the Life of an SRE</a></li>
<li><a href="becoming_sre.html#establishing-a-relationship-to-toil">Establishing a Relationship to Toil</a>
<ul>
<li><a href="becoming_sre.html#what-is-toil">What is toil?</a></li>
<li><a href="becoming_sre.html#whose-toil-are-we-talking-about">Whose Toil Are We Talking About?</a></li>
<li><a href="becoming_sre.html#why-do-sres-care-about-toil">Why do SREs Care about toil?</a></li>
<li><a href="becoming_sre.html#early-vs-established-toil">Early vs Established Toil</a></li>
<li><a href="becoming_sre.html#dealing-with-toil">Dealing with Toil</a>
<ul>
<li><a href="becoming_sre.html#intermediate-to-advanced-toil-reduction">Intermediate to Advanced Toil Reduction</a></li>
</ul>
</li>
<li><a href="becoming_sre.html#go-remove-the-toil">Go Remove the Toil</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="introduction-to-sre"><a class="header" href="#introduction-to-sre">Introduction to SRE</a></h1>
<h2 id="first-things-first"><a class="header" href="#first-things-first">First things first</a></h2>
<blockquote>
<p>Site <strong>Reliability</strong> Engineering is an engineering discipline devoted to
helpings orgs <strong>sustainably</strong> achieve the <strong>appropriate</strong> level of
reliability in their systems, services and products.</p>
</blockquote>
<p>3 key words from definition</p>
<ul>
<li>Reliability: even  if you have the best software in the world, and the best
sales team, if the sw is not up when customers need it, you lose a lot of:
<ul>
<li>Revenue</li>
<li>Time</li>
<li>Reputation</li>
<li>Health</li>
<li>Hiring</li>
</ul>
</li>
<li>Appropriate
<ul>
<li>Usually 100% reliable is not achievable, it is likely that your
dependencies are not 100% reliable.</li>
<li>You need to use <em><strong>service level indicators/service level objectives</strong></em>
(SLI/SLO) to help determine an appropriate level of reliability.</li>
</ul>
</li>
<li>Sustainable
<ul>
<li>If the people in the org are burned out they wont be able to build
reliable systems.</li>
</ul>
</li>
</ul>
<h3 id="sre-vs-devops"><a class="header" href="#sre-vs-devops">SRE vs Devops</a></h3>
<ol>
<li>
<p>SRE implements class devops</p>
</li>
<li>
<p>SRE is to reliability as devops is to delivery</p>
</li>
<li>
<p>It‚Äôs all about the direction</p>
<p><img src="img/sre-vs-devops.png" alt="sre-vs-devops.png" /> <em><a href="https://learning.oreilly.com/library/view/becoming-sre/9781492090540/">Source: Becoming SRE
O'Reilly</a></em></p>
</li>
</ol>
<ul>
<li>Devops go from development to production operations</li>
<li>SRE seems to start on prod operations, and going back to improve the result.</li>
</ul>
<p>Basically these two phrases:</p>
<ul>
<li>Devops thinks, how can I deploy this from my laptop to production</li>
<li>SRE starts at production, how can I make the environment more reliable.</li>
</ul>
<h2 id="sre-mindset"><a class="header" href="#sre-mindset">SRE Mindset</a></h2>
<p>It is born out of curiosity: <em>How does a system work? How does it fail?</em></p>
<p>Zoom out and Zoom in as much as possible, how does the‚Ä¶ work</p>
<ul>
<li>The whole app, development and deployment process</li>
<li>The entire service</li>
<li>The infrastructure</li>
<li>The physical overlay of the infra</li>
<li>The sociotechnical  context in which the infra runs</li>
<li>The org context where the sociotechnical context resides in</li>
</ul>
<h3 id="keeping-focus-on-the-customer"><a class="header" href="#keeping-focus-on-the-customer">Keeping Focus on the Customer</a></h3>
<p>Small example, say you have a 100 servers running a front end pool, suddenly 14
systems fail and are not recovering.  This situation is:</p>
<ol>
<li>No big deal; you can deal with it at your leisure</li>
<li>Something that warrants your immediate attentions. Stop what you are doing
and focus on this</li>
<li>Crisis, even if 2 AM go wake the CEO</li>
</ol>
<p>The answer, <em>it depends</em>, you need to ask, how does this affect the system as a
whole. If the customers wont see anything diff then <strong>a.</strong> If visible by
customers then <strong>b</strong>. If the service is dead in the water and this means no
revenue, go wake the CEO.</p>
<p>So basically you need to ask: <em>What is the intention of the system from the
customer‚Äôs perspective?</em></p>
<h3 id="sres-relationship-with-failure"><a class="header" href="#sres-relationship-with-failure">SRE‚Äôs Relationship with Failure</a></h3>
<p>SRE are very collaborative. Reliability is a collaborative endeavour by nature.</p>
<p>The SRE mindset views errors as an opportunity to learn. Learning from failure
is a core component of an SRE.</p>
<p>SRE treats errors as a signal and we like clear signals. With an SRE mindset
errors can serve the helping understand the system better. This means we need
to surface the errors in addition to eliminate them.</p>
<p>SRE feels ownership of the whole service, t<strong>hey do not say often ‚Äúnot my code,
not my problem‚Äù.</strong> This can be un <em>arma de doble filo.</em> Because of the <strong>yak
shaving issue,</strong> where you go to do one task, say update a package, but then
you check and for the new package you need to upgrade the OS, but to upgrade
the OS you need to‚Ä¶ and you end up with a trimmer in your hands and a yak
infront of you. Taking ownership of the whole range of services and so on, can
lead to this. **</p>
<h3 id="the-mindset-in-motion"><a class="header" href="#the-mindset-in-motion">The Mindset in Motion</a></h3>
<ul>
<li>How does a system work? ‚Üí How will the system work if we scale it?</li>
<li>How does a system work? ‚Üí How can the system work with less operational load
<ul>
<li>SREs are angered by <strong>toil</strong> and the almost allergic reaction it provokes
in them.</li>
</ul>
</li>
<li>How does a system work? ‚Üí How can the system work reliable for more people</li>
</ul>
<h2 id="culture"><a class="header" href="#culture">Culture</a></h2>
<p>Support an enviorment where SREs can thrive.</p>
<ul>
<li>Celebrate the elimination of toil, give SREs opportunity to look for toil and
come up with ideas on how to remove it.</li>
<li>Support curosity</li>
</ul>
<p>Other good way is to support the creation of documentation ‚Äúit is not finished
until it is documented‚Äù</p>
<h3 id="new-hires"><a class="header" href="#new-hires">New hires</a></h3>
<p>For new hires good some good tasks are:</p>
<ul>
<li>Find something unclear, missing or in some way needing improvment on the docs
and fix it.
<ul>
<li>This has the benefit that they need to interact with the docs and read
it, at a deep enough level that they can improve it.</li>
</ul>
</li>
<li>Taking our inline database of all systems on our network, and make sure it
was correct by visiting the locations</li>
</ul>
<h3 id="avoid"><a class="header" href="#avoid">Avoid</a></h3>
<p>How to avoid the incident-handling train of the SRE will always fix everything.</p>
<p>A good question to anwser is ‚ÄúWho is getting smarter and what are we doing
about it?‚Äù The ideal would be that you are getting good new info about your
systems and how they fail.</p>
<p>But if just the SREs are the ones that are learning, you are in reverse, you
are going the opposite direction of culture you are hoping to create.</p>
<p>If the answer is close to: SREs, engineering personnel and relevant stake
holders, you can go to the next question, What is the rest of the org doing
with this knowledge?.</p>
<h3 id="cool-ideas-to-improve-culture"><a class="header" href="#cool-ideas-to-improve-culture"><strong>Cool Ideas to improve culture</strong></a></h3>
<ul>
<li>Start a <strong>postmortem group</strong>,
<ul>
<li>Where someone does a writeup of an issue/outage that happened. Give it in
advance before the meeting, and discuss what could have been done diff,
or proposal on the arch, stuff like that.
<ul>
<li>Good first questions are:
<ul>
<li>What is missing from the write-up we have here?</li>
<li>What do we still not  know, or what may we never know?</li>
<li>Why wasn‚Äôt this worse?</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="sre-advocacy"><a class="header" href="#sre-advocacy">SRE Advocacy</a></h2>
<aside> üí° Side-note: If applying to a job, in the interview process, pay
attention to how **well they are able to articulate their SRE story in the
hiring process.** </aside>
<p>There are two times where SRE Advocacy is most imporant</p>
<ul>
<li>early stages: you need to be able to tell people why they need an SRE</li>
<li>expansion phase: ‚ÄúCool, you‚Äôve been able to set up a new SRE group. Now you
have to get others to play with you. How do are you going to do that?‚Äù</li>
</ul>
<p>Humans are weird to be story-receiving machines. Let‚Äôs go back to the
definition</p>
<blockquote>
<p>Site reliability engineering is the discipline devoted to helping orgs
sustainably achieve an appropriate level of reliability in their systems,
services and products.</p>
</blockquote>
<p>You can tell stories about‚Ä¶</p>
<ul>
<li>Efficacy
<ul>
<li>Partner suffering with reliability issues, SRE got involved and helped
with X, Y and Z and now they are in a better place.</li>
</ul>
</li>
<li>Reputation
<ul>
<li>How famous company X adopted SRE</li>
</ul>
</li>
<li>Possibility
<ul>
<li>How comparable company X adopted SRE, how it went, issues, how they
overcame. If they can you can do it to</li>
</ul>
</li>
<li>Surprise
<ul>
<li>Story about an outage and the surprising result or finding uncovered by
SRE postmortem process</li>
</ul>
</li>
<li>Transformation
<ul>
<li>how things use to be, but now we are in a better place</li>
</ul>
</li>
<li>Puzzle
<ul>
<li>X was a situations that made no sense; here‚Äôs how we solved the mystery
step by step</li>
</ul>
</li>
</ul>
<p>Keep notes on things that happen, the brain is bad at memory stuff.</p>
<p>Add cliffhangers to your stories, ‚Äúall pointed to human error, but something
did not feel right..‚Äù</p>
<p>‚ÄúHere is how I failed and leveled up based on that experience‚Äù</p>
<h1 id="becoming-sre-for-the-individual"><a class="header" href="#becoming-sre-for-the-individual">Becoming SRE for the Individual</a></h1>
<h2 id="preparing-to-be-an-sre"><a class="header" href="#preparing-to-be-an-sre">Preparing to be an SRE</a></h2>
<p>This is not like super mandatory, but will help you a lot with being an SRE:</p>
<h3 id="do-i-need-to-know-how-to-code-yes"><a class="header" href="#do-i-need-to-know-how-to-code-yes">Do I need to know how to code? <strong>Yes</strong></a></h3>
<ul>
<li>If you do not know how something is built your ability to understand it
decreases</li>
<li>Learning how to code will teach you how to debug/troubleshoot</li>
<li>Many tools come in data formats that developers use in their day to day
(JSON, YAML)</li>
</ul>
<h3 id="fundamentals"><a class="header" href="#fundamentals">Fundamentals</a></h3>
<p>Is always good to know about the Big O notation, this will let know people you
know about data structures and efficiency.</p>
<ul>
<li>Single/Basic Systems
<ul>
<li>You need to know how an OS works, about networking, permissions,
protocols and how they fail.</li>
</ul>
</li>
<li>Distributed Systems
<ul>
<li>Almost everything now is a distributed system</li>
</ul>
</li>
<li>Statistics and Data Visualization
<ul>
<li>You need to understand and talk easily about, percentiles, standard
statistical operations, aggregate and compound.</li>
<li>The ability to improve reliability in most situations is predicated on
how to have conversations about data</li>
</ul>
</li>
<li>Storytelling
<ul>
<li>Post incidents reviews and post-mortems are literally tell a story</li>
</ul>
</li>
<li>Be a good person</li>
</ul>
<h3 id="other-nice-to-have"><a class="header" href="#other-nice-to-have">Other nice to have</a></h3>
<ul>
<li>Non-Abstract Large System Design (NALSD)
<ul>
<li>Process of designing and reasoning about large systems</li>
<li>Check <a href="http://highscalabilty.com">highscalabilty.com</a> and chapter 12 of
The Site Reliability Workbook <a href="https://learning.oreilly.com/library/view/the-site-reliability/9781492029496/">oreilly
book/</a>)</li>
</ul>
</li>
<li>Resilience Engineering</li>
<li>Chaos Engineering and Performance Engineering</li>
<li>Machine Learning and Artificial Intelligence</li>
</ul>
<h2 id="getting-to-sre-from"><a class="header" href="#getting-to-sre-from">Getting to SRE from‚Ä¶.</a></h2>
<h3 id="from-devswe"><a class="header" href="#from-devswe">From Dev/SWE</a></h3>
<p>You need to shift your focus to these areas:</p>
<ul>
<li>How does your code really function when in production?
<ul>
<li>How will it behave when the internet can throw any input at it.</li>
<li>What happens if the connection to the DB is slower than in your dev env.</li>
</ul>
</li>
<li>Failure nodes
<ul>
<li>Do you have a good sense on how your code fails?</li>
<li>How can you tell when it is about to fail?</li>
</ul>
</li>
<li>What have you built into the code to make figuring out whether your code is
running well easy or possible?</li>
<li>How easy have you made handle upgrades?
<ul>
<li>and rollbacks?</li>
</ul>
</li>
<li>Have you written good docs on for an SRE audience?</li>
</ul>
<p>Basically: How much do you think about running your systems in additions to
building them?</p>
<h3 id="from-sysadmin"><a class="header" href="#from-sysadmin">From Sysadmin</a></h3>
<p>Sysadmins live to serve, they bridge the gap between technology and the people
that use it.</p>
<p>You already have a good well-exercised skill for troubleshooting and debugging.</p>
<p>Do exercises in SadServers, like leet code but for infrastructure.</p>
<p>Change you mindset from ‚Äúmonitor all the things‚Äù to ‚Äúmeasure reliability from
the customer perspective, not the component perspective‚Äù</p>
<p>Using terms like ‚Äúcontributing factors‚Äù instead of ‚Äúroot cause‚Äù can change both
your internal and external way of looking at an issue. More on this on chapter
10.</p>
<p>Since you are already answering tickets, getting emails on things failing, you
can start using that as a data set to start measure the reliability of the
systems and how/why they fail.</p>
<h3 id="more-advice"><a class="header" href="#more-advice">More advice</a></h3>
<p>Do not forget to track your progress, so you have something to look at when
they reject you from an interview, or when you feel indifference to your ideas.</p>
<h2 id="hints-for-getting-hired-as-an-sre"><a class="header" href="#hints-for-getting-hired-as-an-sre"><strong>Hints for Getting Hired as an SRE</strong></a></h2>
<p>Some general advice of getting hired as an SRE</p>
<h3 id="looking-closely-at-the-job-posting"><a class="header" href="#looking-closely-at-the-job-posting">Looking closely at the job posting</a></h3>
<p>Few thing to check:</p>
<ul>
<li>The tech mentioned
<ul>
<li>Modernity of the tech</li>
<li>How items hand together
<ul>
<li>k8s/prometheus makes sense, k8s/nagios does not</li>
</ul>
</li>
<li>Mention of Ticketing System
<ul>
<li>How quickly will things move in that env if its ticket based.</li>
</ul>
</li>
<li>Specific versions of sw
<ul>
<li>they need a very specific thing</li>
</ul>
</li>
<li>Mix of on-premise and cloud products
<ul>
<li>Are they all in the same env?</li>
</ul>
</li>
<li>Mention of programming languages
<ul>
<li>Coding has meaning to them</li>
</ul>
</li>
<li>Heavily skewed toward CI/CD and env provisioning tools
<ul>
<li>May have been a devops position, which is a diff mindset</li>
</ul>
</li>
<li>Presence or absence of a monitoring tech
<ul>
<li>What connection if any would monitoring have to this role?</li>
</ul>
</li>
<li>Services that are consumed
<ul>
<li>What am i getting into from dependencies perspective</li>
</ul>
</li>
</ul>
</li>
<li>The human connection
<ul>
<li>Look for an indication of the stakeholders or collaborators</li>
</ul>
</li>
</ul>
<p>Look for post-incidents reviews, they can be a helpful way of how they handle
issues, what‚Äôs their SW stack and stuff like that. Do not bring that up in the
interview unless they do.</p>
<h3 id="preparing-for-an-sre-interview-resources"><a class="header" href="#preparing-for-an-sre-interview-resources">Preparing for an SRE interview (Resources)</a></h3>
<p>Depends (of course) of the posting, it could be more SWE focus, or CI/CD focus,
but there are four things you need to study for the interviews:</p>
<ul>
<li>
<p><em><strong>NALSD (non-abstract large system design)</strong></em></p>
<p>For systems that require scale (most of them)</p>
<p>Resources:</p>
<ul>
<li><em>The Site Reliability Workbook</em>¬†has a lovely chapter on the topic.</li>
<li>There are a lot of talks on the topic <a href="https://www.youtube.com/@UsenixOrg">USENIX</a></li>
<li>Google has a public classroom for this
<a href="https://sre.google/classroom/">https://sre.google/classroom/</a></li>
</ul>
</li>
<li>
<p><em><strong>Monitoring/observability</strong></em></p>
<p>Good places to start:</p>
<ul>
<li><em>Practical Monitoring</em>¬†by Mike Julian (O‚ÄôReilly, 2017)</li>
<li><em>Observability Engineering</em>¬†books by Charity Majors et al. (all from
O‚ÄôReilly)</li>
</ul>
<p>If you expect to talk about SLIs and SLOs review</p>
<ul>
<li><em>Implementing Service Level Objectives</em>(O‚ÄôReilly, 2020).</li>
</ul>
</li>
<li>
<p><em><strong>Computing Fundamentals</strong></em></p>
<ul>
<li>Computer science, computer networks, linux, distributed computing, stuff
like that.</li>
</ul>
</li>
<li>
<p><em><strong>Troubleshooting and debugging</strong></em></p>
<ul>
<li>Hopefully you have experience with this one, but
<a href="http://sadservers.com">sadservers.com</a> is a good start</li>
</ul>
</li>
</ul>
<h3 id="what-to-ask-at-the-sre-interview"><a class="header" href="#what-to-ask-at-the-sre-interview">What to ask at the SRE Interview</a></h3>
<p>Some good conversation starters:</p>
<ul>
<li>
<p><strong>Tell me about your monitoring system</strong></p>
<p>This exposes all sort of info on organization, structure, collaboration,
ownership, How decision are made, and so on.</p>
<p>Some follow up questions:</p>
<ul>
<li>Who owns monitoring in your org?</li>
<li>How many monitoring systems are there in active use?</li>
<li>Who (apps/services/teams) send data to those systems, and who access
them?</li>
<li>How easy it is to onboard a new app/service to your monitoring?</li>
<li>What decisions are made using the data?</li>
<li>Are there alerts generated fromt his system?</li>
<li>What makes you happy and unhappy with your current system?</li>
</ul>
</li>
<li>
<p><strong>Tell me about your post-incidents review process</strong></p>
<p>Here you are trying to see how intentional are they on learning from
failure</p>
<ul>
<li>Do you hold post-incidents review after your outages?</li>
<li>What is their purpose?</li>
<li>Who is ‚Äúin the room‚Äù for them?</li>
<li>How do you document your outages?</li>
<li>Can you tell me (at whatever level of details you are comfortable) about
a recent outage</li>
<li>Do you have a sense of the most common classes of outage you have seen in
the last N month? (config related, overload/resource-deprivation
failures, code bug)</li>
</ul>
</li>
<li>
<p><strong>Tell me about you on-call setup</strong></p>
<ul>
<li>Do people get time off after incidents?</li>
<li>Who in the org participates in an on-call rotation (just SREs? Devs?
Managers?)</li>
<li>When was the last time you personally were ‚Äúpaged‚Äù?</li>
<li>Do people get paged equally often between work and off-work hours?</li>
</ul>
</li>
<li>
<p><strong>What problem does SRE exist to address in your org?</strong></p>
<ul>
<li>If they cannot answer that: What are some ‚Äòrecent wins‚Äô by SRE in the
past 6 to 12 months?</li>
</ul>
</li>
<li>
<p><strong>Can SREs check in code to major repos in your org?</strong></p>
<ul>
<li>You‚Äôll see how involved is the SRE with dev work</li>
</ul>
</li>
</ul>
<h2 id="a-day-in-the-life-of-an-sre"><a class="header" href="#a-day-in-the-life-of-an-sre">A Day in the Life of an SRE</a></h2>
<p>Because of the nature of the SRE role, it is hard to describe an average day,
since it most days are different to each other. So instead of an average day,
we have different modes SREs can relate to. Look at it like different hats an
SRE will wear</p>
<ul>
<li>
<p><strong>Incident/Outage Mode</strong></p>
<p>There will be days were most of your time you will be involved dealing with
an accident. These days come with some feelings attached to them (fear,
anxiety, and so on), the intensity of these feelings depend on the severity
of the outage.</p>
<p>When on this mode you will be reacting not planning it is normal.</p>
</li>
<li>
<p><strong>Post-incident Learning Mode</strong></p>
<p>After the incident now you have the opportunity to review the memories of
an outage and learn from it.</p>
<p>You are responsible for documenting it, in a way others can understand it.
To do this you will have to investigate a bit, look for data in your
monitoring systems, talk to your colleagues to discover what they knew and
when.</p>
</li>
<li>
<p><strong>Builder/Project/Learn Mode</strong></p>
<p>This is when you actually have time to sit and...</p>
<ul>
<li>Devlop some code for services or SRE tasks</li>
<li>Provision new envs or infra</li>
<li>Improve monitoring/observability</li>
<li>Removing toil</li>
<li>Writing docs</li>
<li>Learning a new tech in anticipation of using it some day</li>
</ul>
<p>Of course, there will be times when you are doing boring stuff, but that
can help you identify toil you need to remove.</p>
</li>
<li>
<p><strong>Architecture Mode</strong></p>
<p>Depends on your org, but, and SRE should be showing up to design and
planning meetings where they are acting as a representative  for
reliability.</p>
<p>Be political about it, no one wants to hear, "<em>this would have never happen
if there was an SRE when this thing was designed</em>". Appeal to the sense
that everyone want to have their code in production be as reliable as
possible.</p>
</li>
<li>
<p><strong>Management Mode</strong></p>
<p>If the response to, <em>what did you do all day?</em>, was, <em>I went to meetings</em>,
do not worry, chances are you might be an SRE manager.</p>
</li>
<li>
<p><strong>Planning Mode</strong></p>
<p>Some portion of your day will be planning.</p>
<ul>
<li>Implementation plans</li>
<li>Capacity planning</li>
<li>Self-definitional work (goals of SRE team and stuff like that)</li>
</ul>
</li>
<li>
<p><strong>Collaboration Mode</strong></p>
<p><mark> The SRE role is relentlessly collaborative.</mark></p>
<p>When you implement SLI/SLO (Service Level Indicators/Service Level
Objectives) you will be working with: devs, PMs, stakeholders.</p>
<p>Another example of collaborative work, is what some people call pre-launch
review. An SRE gets involved to revise the service being deployed in
production, what is necessary for it to run reliably in production</p>
<p>Do not be a gatekeeper, share this work with the devs and the stakeholders,
collaborate as much as possible</p>
<p>Finally, listen to the customers through monitoring work. The SLIs/SLOs
(Service Level Indicators, Service Level Objectives) are meant to provide
ongoing collaboration with the customer.</p>
</li>
<li>
<p><strong>Recovery and Self-Care Mode</strong></p>
<p>Burn out SREs are of no good to anyone. Because of the nature of SREs it
can be easy to overextending yourself. But when we hear that someone is
regularly working 60-75 hours, is not something to be proud of, that means
there is a failure in the system and needs to be fixed.</p>
<p>You need to have recovery time.</p>
</li>
<li>
<p><strong>On Balance</strong></p>
<p>Balance is something good to strive for, but there are often situational
factors  that complicate the effort, for example, an <em>early service</em> vs <em>mature
service</em>, new services are always noisier and require more reactive work. They
also provide more toil to be stripped away, so maybe you expend more time in
one of these modes than in others.</p>
<p>The idea is to see this as weather patterns, I know it is going to rain hard
for some time, but I mentally prepare. Ideally things will level out. If not,
you need to strive for it. SRE attempts to be a <strong>sustainable</strong> operations
practice. If you realise this cannot be sustained maybe you need to start
looking for a different job.</p>
</li>
</ul>
<h2 id="establishing-a-relationship-to-toil"><a class="header" href="#establishing-a-relationship-to-toil">Establishing a Relationship to Toil</a></h2>
<blockquote>
<p>If a human operator needs to touch  your system during normal operations, you
have a bug. The definition of normal changes are your systems grow.</p>
</blockquote>
<blockquote>
<p>Carla Geisser, Google SRE</p>
</blockquote>
<h3 id="what-is-toil"><a class="header" href="#what-is-toil">What is toil?</a></h3>
<p>First of all we need to define toil. Toil is not the work you do not like to do
or simply repetitive chores. Toil is the kind of work when running a production
service, that to tends to be:</p>
<ul>
<li>
<p>Manual
Work like manually running a script that automates a task is still manual,
the time that a human spends running the script is still toil time</p>
</li>
<li>
<p>Repetitive
Toil is work you do over and over.</p>
</li>
<li>
<p>Automatable
If human judgment is essential for the task, there is a good chance it is
not toil.</p>
</li>
<li>
<p>Tactical
Toil is reactive rather than strategy-driven.</p>
</li>
<li>
<p>Does not bring enduring value
If your service is in the same state after you finished a task, the task
was probably toil.</p>
</li>
<li>
<p>O(n) with service growth
If the work  involved scales linearly with the size of the service (traffic
volume, service size) is it probably toil.</p>
</li>
</ul>
<p>We need to have less toil because it tends to expand, if left unchecked  it can
quickly fill 100% of everyone's time, and people will stop doing <em>Engineering
Work</em>. What is that? Engineering work is novel and requires human judgment. It
produces permanent improvement in your service and is guided by strategy.</p>
<p>Now that we know what toil is, lets see the relationship SREs have to it.</p>
<h3 id="whose-toil-are-we-talking-about"><a class="header" href="#whose-toil-are-we-talking-about">Whose Toil Are We Talking About?</a></h3>
<p><em>Whose toil is it?</em> On opposed to other parts of SRE where we are customer
focuses, here we need to focus on our toil, not the customers one. Sure, they
might have a connection for example, operational toil (ours) is exposed to the
customer if they have to go into 4 steps to make a request. But we need to keep
the main focus on the operational toil.</p>
<h3 id="why-do-sres-care-about-toil"><a class="header" href="#why-do-sres-care-about-toil">Why do SREs Care about toil?</a></h3>
<p>An argument can be made that if you remove toil a system becomes more reliable,
but the author suggests that sometimes this is not the case. An that SREs
because of their nature, are inclined to  eliminate toil because of the
following reasons.</p>
<ul>
<li>
<p>Aesthetics
SREs want to eliminate toil because if offends their aesthetic
sensibilities. Toil is inelegant, inefficient, unnecessary, suboptimal,
hard to look at. That simply is a reason to remove it.</p>
</li>
<li>
<p>Money
Orgs have many reasons to want their expensive people do work that is
significant  that make the revenue forward, meaning the antithesis of toil.</p>
</li>
<li>
<p>Job Satisfaction</p>
</li>
</ul>
<h3 id="early-vs-established-toil"><a class="header" href="#early-vs-established-toil">Early vs Established Toil</a></h3>
<p>When an app is developed it is likely to have more toil than once it is
established. Why? Developers care about making a solution to a customer
problem, not making their app be super operational. They can be, and that is
why it is important that an SRE is in the room when planning the Architecture
for the app, but it is likely that it will have more toil than an established
one.</p>
<p>It is important to note this, because now we can mentally prepare for it, we
now know that there will be a finite period of work with a lot of toil, but it
is expected and it will end.</p>
<h3 id="dealing-with-toil"><a class="header" href="#dealing-with-toil">Dealing with Toil</a></h3>
<p>Usually people just say, automate it, and the toil will go away. But the author
propose the idea that similar to matter that toil is not created and cannot be
destroyed just transformed.</p>
<p>When you are automating a task, the toil did not disappeared it just got
transformed into a different thing: <em>Complexity</em>. Usually this is a wise
bargain to take, but it is important to keep in mind that it has its  trade
offs.</p>
<h4 id="intermediate-to-advanced-toil-reduction"><a class="header" href="#intermediate-to-advanced-toil-reduction">Intermediate to Advanced Toil Reduction</a></h4>
<p>It is important to keep track of the toil we remove on individual systems,
management will love to hear that X system required N manual steps and now it
was automated and require N-4 steps. But once you pass that first stage you
also need to start thinking. How can I reduce the toil we are going to have?</p>
<h3 id="go-remove-the-toil"><a class="header" href="#go-remove-the-toil">Go Remove the Toil</a></h3>
<p>That is pretty much it for this chapter, we defined what toil is and how to
deal with it. Go and put in practice what you have read here.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-k8s"><a class="header" href="#-k8s">‚õµÔ∏è k8s</a></h1>
<p>Super surprised someone still writes the full <em>Kuberenetes</em> word instead of
<em>k8s</em>. K8s looks way cooler</p>
<p>Specific k8s stuff</p>
<ul>
<li><a href="/k8s_up_and_running.html">üêã k8s up and running</a></li>
<li><a href="/k8s_cheatsheet.html">üìù k8s cheatsheet</a></li>
</ul>
<p>Things surrounding k8s</p>
<ul>
<li><a href="/helm.html">‚éà helm</a> (it has a really good intro on k8s)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-ckad-preparation"><a class="header" href="#-ckad-preparation">üìú ckad preparation</a></h1>
<blockquote>
<p>‚ö†Ô∏è  these are notes taken from the ckad prep course by o'reily
<strong>please go read it and just use this as reference</strong>.</p>
</blockquote>
<ul>
<li><a href="./ckad_prep_1.html">k8s in a nutshell</a></li>
<li><a href="./ckad_prep_2.html">object management</a></li>
<li><a href="./ckad_prep_3.html">application design and build</a></li>
</ul>
<p>Also if you only want to know what to focus on.</p>
<ul>
<li><a href="./ckad_focus.html">CKAD focus topics</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="k8s-in-a-nutshell"><a class="header" href="#k8s-in-a-nutshell">k8s in a nutshell</a></h1>
<aside>
üí° For more in depth explanations, please go to
 [k8s up and running](./k8s_up_and_running.md)
</aside>
<h2 id="high-level-k8s-arch"><a class="header" href="#high-level-k8s-arch">High level k8s arch</a></h2>
<p>A k8s cluster has two kind of nodes</p>
<ul>
<li><strong>control plane node</strong>: exposes the k8s API, so if you want to interact with
the k8s cluster you need to go thru here.</li>
<li><strong>worker node</strong>: nodes that execute the workload. Needs to have a container
runtime engine installed (containerd) for executing the containers.</li>
</ul>
<h3 id="control-plane-node-components"><a class="header" href="#control-plane-node-components">Control Plane Node Components</a></h3>
<ul>
<li>API server: expose k8s api</li>
<li>Scheduler: Watches for new k8s pods and assign to nodes</li>
<li>Controller Manager: watches the state of cluster, and makes changes</li>
<li>etcd: a key-value that captures the state of the objects we create in the
cluster</li>
</ul>
<h3 id="common-node-components"><a class="header" href="#common-node-components">Common Node Components</a></h3>
<p>Any node has these:</p>
<ul>
<li>
<p>Kubelet: agent that makes sure the containers are running in a k8s pod,
usually this one runs in the workers.</p>
</li>
<li>
<p>kube proxy: maintain network rules and allow communication</p>
</li>
<li>
<p>Container runtime: software responsible for running containers</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="object-management"><a class="header" href="#object-management">Object Management</a></h1>
<p>Hybrid approach for managing objects.</p>
<p>First you create the yaml automatically with the <code>run</code> command</p>
<pre><code class="language-bash">k run nginx --image=nginx --dry-run=client -o yaml &gt; nginx-pod.yaml
</code></pre>
<p>Then you can edit it with <code>vi</code> or smth,</p>
<pre><code class="language-bash">vi nginx-pod.yaml
</code></pre>
<p>And then you actually create the object out of the yaml file:</p>
<pre><code class="language-bash">k create -f ngnix-pod.yaml
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="application-design-and-build"><a class="header" href="#application-design-and-build">Application Design and Build]</a></h1>
<p>Here are the modules for this part of the cert.</p>
<ol>
<li><a href="ckad_prep_3.html">Container Images</a></li>
<li><a href="ckad_prep_4.html">Pods</a></li>
<li><a href="ckad_prep_5.html">Jobs and CronJobs</a></li>
<li><a href="ckad_prep_6.html">Container Storage</a></li>
<li><a href="./ckad_prep_7.html">Multi-Container Pods</a></li>
<li><a href="./ckad_prep_8.html">Labels and Annotations</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="container-images"><a class="header" href="#container-images">Container Images</a></h1>
<ul>
<li><a href="ckad_prep_3.html#image-and-container-management">Image and Container Management</a></li>
<li><a href="ckad_prep_3.html#learnings-from-the-lab">Learnings from the Lab</a></li>
</ul>
<h2 id="image-and-container-management"><a class="header" href="#image-and-container-management">Image and Container Management</a></h2>
<p>Glossary.</p>
<ul>
<li>Container: package and app into a single unit</li>
<li>Container Runtime Engine: sw that executes your container (docker engine)</li>
<li>Container Orchestrator: automates and mages workload  (k8s)</li>
<li>ContainerFile: Instructions to build the container</li>
<li>Container Image: packages app into a single unit of sw including its runtime,
env and config</li>
<li>Container Registry: where to share your container</li>
</ul>
<p>Render local images you have in your machine.</p>
<pre><code>docker images
</code></pre>
<p>Before pushing a docker container image to a registry we need to conform to the
conventions of the registry</p>
<p>For example, for docker registry you need to prepend your container image with
your username:</p>
<pre><code>docker tag python-hello-world:1.0.0 jose/python-hello-world:1.0.0
</code></pre>
<p>If you want to push your container image, you need to auth first,</p>
<pre><code>docker login --username=jose
</code></pre>
<p>And then push it</p>
<pre><code>docker push jose/python-hello-world:1.0.0
</code></pre>
<p>You can create a backup of container image into a <code>.tar</code> file</p>
<pre><code class="language-bash">docker save -o python-hello-world.tar jose/python-hello-world:1.0.0
</code></pre>
<p>Then list it</p>
<pre><code class="language-bash">$ ls
python-hello-world.tar
</code></pre>
<p>We can do the inverse from a file:</p>
<pre><code class="language-bash">docker load --input python-hello-world.tar
</code></pre>
<h1 id="learnings-from-the-lab"><a class="header" href="#learnings-from-the-lab">Learnings from the Lab</a></h1>
<p>Create the container</p>
<p><code>cd</code> into the dir with the Dockerfile, then do:</p>
<pre><code class="language-bash">docker build -t some-tag:1.0.0 .
</code></pre>
<p>The dot is important</p>
<p>You can double check if you did it right with</p>
<pre><code class="language-bash">$ docker images
REPOSITORY           TAG       IMAGE ID       CREATED         SIZE
nodejs-hello-world   1.0.0     3af6d05d3c35   8 minutes ago   180MB
</code></pre>
<p>Then to actually run the thing,</p>
<pre><code class="language-bash">docker run -d -p 80:3000 nodejs-hello-world:1.0.0
</code></pre>
<p>Keep in mind that all the flags go before the image tag, if not it will trip</p>
<p>To list the running containers you can do</p>
<pre><code>$ docker container ls
CONTAINER ID   IMAGE                      COMMAND                  CREATED         STATUS         PORTS                                   NAMES
c02c36ecbc85   nodejs-hello-world:1.0.0   "docker-entrypoint.s‚Ä¶"   3 minutes ago   Up 3 minutes   0.0.0.0:80-&gt;3000/tcp, :::80-&gt;3000/tcp   angry_mestorf
</code></pre>
<p>To stop it you can do</p>
<pre><code>docker container stop  angry_mestorf
</code></pre>
<p>Saving to a tar file:</p>
<pre><code>docker save -o nodejs-hello-world-1.0.0.tar nodejs-hello-world:1.0.0
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pods"><a class="header" href="#pods">Pods</a></h1>
<ul>
<li><a href="ckad_prep_4.html#running-and-config-applications-in-containers-with-pods">Running and config applications in containers with pods</a></li>
<li><a href="ckad_prep_4.html#namespace">Namespace</a></li>
</ul>
<p>Go read more on pods <a href="./k8s_up_and_running_4.html">here</a></p>
<h2 id="running-and-config-applications-in-containers-with-pods"><a class="header" href="#running-and-config-applications-in-containers-with-pods">Running and config applications in containers with pods</a></h2>
<p>Creating a pod with imperative command (probably we will never do this?)</p>
<pre><code class="language-bash">$ k run hazelcast \
    --image=hazelcast/hazelcast \
    --restart=Never \
    --port=5701 \
    --env="DNS_DOMAIN=cluster" \
    --labels="app=hazelcast,env=prod" \

</code></pre>
<p>In <code>yaml</code> would look something like this.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata: v1
    name: hazelcast
spec:
    containers:
    - image: hazelcast/hazelcast
    - name: hazelcast
      ports
      - containerPort: 5701
    restartPolicy: Never
</code></pre>
<p>The container runtime engine will download the image from the registry and
store it in that pod.</p>
<p>Pod Life Cycle Phases</p>
<pre><code>Pending -&gt; Running -&gt; Succeeded
                  |
                   -&gt; Failed
</code></pre>
<p>Create a temporary pod, for experimentation, for example here we create a pod
to see if it can communicate with the ip provided.</p>
<pre><code class="language-bash">k run busybox \
    --image=busybox \
    --rm \ # this will  remove the pod after creation
    -it
    --restart=Never
    -- wget 10.1.0.41
</code></pre>
<p>We can overwrite the entry point of a container, in the manifest</p>
<pre><code class="language-yaml"># more stuff
spec:
    containers:
    - image: some/image
      name: spring-boot
      command: ["/bin/sh"]
      args: ["-c", "while true; do date; sleep 10; done"]
</code></pre>
<p>Here we use <code>command</code> and <code>args</code> to overwrite the entrypoint.</p>
<p>If you want to delete a pod without graceful deletion, you can do:</p>
<pre><code class="language-bash">k delete -f pod.yaml --now
</code></pre>
<h2 id="namespace"><a class="header" href="#namespace">Namespace</a></h2>
<p>Groups resources for ease of organize.</p>
<p>Namespaces starting with <code>kube-</code> are not consider end user-namespaces, when
you are a developer you wont need to interact with those.</p>
<p>If you delete a namespace, everything that it contains will be deleted as well</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jobs-and-cronjobs"><a class="header" href="#jobs-and-cronjobs">Jobs and CronJobs</a></h1>
<ul>
<li><a href="ckad_prep_5.html#job">Job</a></li>
<li><a href="ckad_prep_5.html#cronjob">CronJob</a></li>
</ul>
<p>One-time operations and scheduled operations.</p>
<p>Here is the difference between these k8s primitives.</p>
<ul>
<li>Pod: we use this for <strong>continuous</strong> operation, for example a web app that has
an API on it.</li>
<li>CronJob: a job we run periodically, for example: running a database backup</li>
<li>Job: runs only one time, for example, import/export data processes.</li>
</ul>
<h2 id="job"><a class="header" href="#job">Job</a></h2>
<p>We define a number of completions of a job and the actual work wont be consider
to be comleted until we reach that number of completions.</p>
<p>The work is managed by a <code>Job</code> but it will still run inside a Pod</p>
<p>K8s will not delete these objects once they finish, this helps for debugging
purposes.</p>
<p>To create a job imperative:</p>
<pre><code class="language-bash">$ k create job \
    counter \
    --image=ngnix:1.24
    -- /bin/sh -c 'counter=0; while [ $counter -lt 3 ]; do \
       counter=$((counter+1)); echo "$counter"; sleep 3; done'
</code></pre>
<pre><code class="language-yaml">apiVersion: batch/v1
kind: Job
metadata:
    name: counter
spec:
    completions: 1
    parallelism: 1 # do we want this to be exectued in parallel
    backoffLimit: 6 # if fails n times, mark it as failed
    template:
        spec:
            restartPolicy: OnFailure # restart pod when fail or start a new pod
            contianers:
            - args:
                - /bin/sh
                - -c
                - ...
                image: nginx:1.24.0
                name: counter

</code></pre>
<p>There are different operation types for a job. The default behaviour is to run
in a single pod and expect one successful operation. But we can:</p>
<ul>
<li><code>spec.completions</code> change the number of times we want to execute it</li>
<li><code>spec.parallelism</code>  executing a workload by multiple pods in parallel</li>
<li><code>spec.backoffLimit</code> number of retries until the job is marked as successful</li>
<li><code>spec.template.spec.restartPolicy</code> need to be declared explicitly, can only
be <code>OnFailure</code> or <code>Never</code></li>
<li><code>spec.activeDeadlineSeconds</code> if the job is not completed in this amount of
time, terminate it. This takes precedence over <code>backoffLimit</code></li>
</ul>
<p>You can check the events of a job either from the description or with this:</p>
<pre><code class="language-bash">k events --for job/printer -n batch
</code></pre>
<h2 id="cronjob"><a class="header" href="#cronjob">CronJob</a></h2>
<p>It is a primitive for executing workloads periodically. It uses the same
notation as unix for repetition.</p>
<p>The cronjob will create <code>Jobs</code>, so we can do <code>k get jobs</code> and see the ones that
the <code>cronjob</code> has created</p>
<p>We can retain history for the jobs. The default for the successful ones is
(<code>spec.successfullJobsHistoryLimit</code>) set to 3.</p>
<p>The default for the failed ones (<code>spec.failedJobsHistoryLimit</code>) is 1</p>
<p>Imperative command to create a cronjob.</p>
<pre><code class="language-bash">k create cronjob current-date \
    --schedule="* * * * *"
    --image=nginx:1.24.0.0
    -- /bin/sh -c 'echo "Current date: $(date)"'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="container-storage"><a class="header" href="#container-storage">Container Storage</a></h1>
<ul>
<li><a href="ckad_prep_6.html#volumes">Volumes</a>
<ul>
<li><a href="ckad_prep_6.html#volume-types">Volume Types</a></li>
<li><a href="ckad_prep_6.html#ephemeral-volume">Ephemeral Volume</a></li>
<li><a href="ckad_prep_6.html#persistent-volume">Persistent Volume</a>
<ul>
<li><a href="ckad_prep_6.html#access-modes">Access Modes:</a></li>
<li><a href="ckad_prep_6.html#reclaim-policy">Reclaim Policy:</a></li>
</ul>
</li>
<li><a href="ckad_prep_6.html#how-to-use-it">How to use it.</a></li>
</ul>
</li>
</ul>
<h2 id="volumes"><a class="header" href="#volumes">Volumes</a></h2>
<p>The containers have a temporary file system, if you restart the container the
file system will be deleted.</p>
<ul>
<li>Ephemeral Volumes: exist for the lifespan of a pod. Useful for sharing data
between multiple containers running in a pod</li>
<li>Persistent Volumes: preserve data beyond the lifespan of a pod.</li>
</ul>
<p>Define a volume using <code>spec.volumes[]</code> and then reference it in a container
with <code>spec.containers[].volume.volumeMounts</code></p>
<h3 id="volume-types"><a class="header" href="#volume-types">Volume Types</a></h3>
<p>There are a lot, some are only offered by certain cloud providers.</p>
<p>Some of the common ones:</p>
<ul>
<li><code>emptyDir</code>: Empty dir in a pod with read/write access. Ephemeral.</li>
<li><code>hostPath</code>: Point to a file in the host.</li>
<li><code>configMap</code>: Mount config data</li>
<li><code>nfs</code>: provide a network file system. Persistent.</li>
</ul>
<h3 id="ephemeral-volume"><a class="header" href="#ephemeral-volume">Ephemeral Volume</a></h3>
<p>We need to define the volume first in <code>spec.volumes</code> and then reference it
inside <code>spec.containers.volumeMounts</code></p>
<p>Here is an example:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata: Pod
    name: my-container
spec:
    volumes:
    - name: logs-volume
      emptyDir: {}
    containers:
    - image: nginx
      name: my-container
      volumeMounts:
      - mounthPath: /var/logs
        name: logs-volume
</code></pre>
<h3 id="persistent-volume"><a class="header" href="#persistent-volume">Persistent Volume</a></h3>
<p>We need to create two more objects to create this type of volume.</p>
<ul>
<li><code>PersistentVolume</code> (PV): piece of storage in the cluster provisioned by an admin</li>
<li><code>PersistentVolumeClaim (PVC)</code>: consumes PV, similar to how a pod consumes
node resources (cpu, memory) here the <code>pvc</code> consumes storage from a <code>pv</code></li>
</ul>
<p>There are different ways on how we can provision this type of storage.</p>
<ul>
<li>static provisioning: we create the <code>PersistentVolume</code> object by ourselves.</li>
<li>dynamic provisioning: automatically creates the <code>PersistentVolume</code> object</li>
<li>storage class: obj/s that already exist in the k8s cluster. (setup by admin)</li>
</ul>
<p>Defining a <code>PersistentVolume</code></p>
<p>We need to set <em>capacity</em>, <em>access mode</em>, and <em>host path</em></p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolume
metadata:
  name: db-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/db
</code></pre>
<h4 id="access-modes"><a class="header" href="#access-modes">Access Modes:</a></h4>
<ul>
<li><code>ReadWriteOnce</code>: rw by single node</li>
<li><code>ReadOnlyMany</code>: r by many nodes</li>
<li><code>ReadWriteMany</code>: rw by many nodes</li>
<li><code>ReadWriteOncePod</code>: rw mounted by a single pod</li>
</ul>
<h4 id="reclaim-policy"><a class="header" href="#reclaim-policy">Reclaim Policy:</a></h4>
<ul>
<li><code>Retain</code>: default. When PVC (persisted volume claim) is deleted the pv is
released and can be reclaimed.</li>
<li><code>Delete</code>:  Deletion removes PV and associated storage.</li>
</ul>
<h3 id="how-to-use-it"><a class="header" href="#how-to-use-it">How to use it.</a></h3>
<p>So once we have our <code>pv</code>, we need to create a <code>pvc</code> to claim storage from that
<code>pv</code>.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: db-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 8Gi
  storageClassName: "" # empty means we will use a statically-created pv
</code></pre>
<p>When we create it we need to check that the state is <code>Bound</code>.</p>
<p>In the pod, we create the volume as regular and assign it to the container.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  volumes:
    - name: app-storage
      persistentVolumeClaim:
        claimName: db-pvc # reference the volume by pvc name
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: "/mnt/data"
        name: app-storage
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-container-pods"><a class="header" href="#multi-container-pods">Multi-Container Pods</a></h1>
<p>In general we want to define 1 container per pod. That is the case when we want
to operate a microservice on that container.</p>
<p>But there are reasons to run multiple ones. For example, helper containers, run
setup scripts, stuff like that.</p>
<h2 id="design-patterns"><a class="header" href="#design-patterns">Design Patterns</a></h2>
<p>Emerged from pod requirements</p>
<ul>
<li>
<p>Init Container: initialization logic, that need to be run before the main app
starts.</p>
<ul>
<li>Example: Downloading config files required by the application.</li>
</ul>
</li>
<li>
<p>Sidecar: containers not part of the main traffic the app receives, but will
run along side the main app</p>
<ul>
<li>Example: Watcher capabilities.</li>
</ul>
</li>
<li>
<p>Adapter: Transform output produced by app into another format or smth that
makes it more usable for another program.</p>
<ul>
<li>Example: Massaging log data</li>
</ul>
</li>
<li>
<p>Ambassador: Provides a proxy for communicating with external services. To
abstract complexity.</p>
<ul>
<li>Example: providing credentials for auth.</li>
</ul>
</li>
</ul>
<h3 id="init-container"><a class="header" href="#init-container">Init Container</a></h3>
<p>To define an <code>initContainer</code> you need to add this to your <code>yaml</code>.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: myapp
spec:
  initContainers:
  - name: app-init
    image: busybox:1.28
    command: ['sh', '-c', "wget something.com/res.png"]
  containers:
  - name: myapp-container
    image: busybox:1.28
    command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600']
</code></pre>
<p>When we start the pod, under <code>STATUS</code> you can see <code>Init:0/1</code> meaning it is
creating the containers needed.</p>
<p>We can talk with any of the containers using <code>--contianer</code> or <code>-c</code>.</p>
<pre><code class="language-bash">k --container=init
k --container=app
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="labels-and-annotations"><a class="header" href="#labels-and-annotations">Labels and Annotations</a></h1>
<ul>
<li><a href="ckad_prep_8.html#labels">Labels</a></li>
<li><a href="ckad_prep_8.html#annotation">Annotation</a></li>
</ul>
<p>Labels:</p>
<ul>
<li>Key value pairs that can be assigned to an object</li>
<li>They need to follow a naming convention, we can use them to filter objects</li>
</ul>
<p>Annotations:</p>
<ul>
<li>Represent human-readable metadata</li>
<li>Not meant for query</li>
</ul>
<h2 id="labels"><a class="header" href="#labels">Labels</a></h2>
<p>We can assign it with the imperative <code>label</code> command, or with
<code>metadata.labels[]</code>.</p>
<p>Not meant for elaborate. They have a max of 63 characters.</p>
<p>We can add a label imperatively with:</p>
<pre><code class="language-bash">k label pod nginx tier=backend env=prod app=viraccle
</code></pre>
<p>See pods with labels</p>
<pre><code class="language-bash">k get pods --show-labels
</code></pre>
<p>To remove a label you put the key and a minus sign</p>
<pre><code class="language-bash">k label pod nginx tier-
</code></pre>
<p>From a manifest.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: label-demo
  labels:
    environment: production
    app: nginx
</code></pre>
<p>We can use them to query stuff.</p>
<pre><code class="language-bash">$ k get pods -l tier=frontend,env=dev --show-labels
$ k get pods -l version --show-labels # only the key
$ k get pods -l 'tier in (frontend,backend),env=dev' # create a query
</code></pre>
<p>There is other k8s objects that enforce policies or smth, and that can also use
the labels to select to which pod you want to enforce them.  For example a
<code>NetworkPolicy</code> can have <code>spec.podSelector.matchLabels.mylabel: frontend</code>.</p>
<h2 id="annotation"><a class="header" href="#annotation">Annotation</a></h2>
<p>Metadata without the ability to be queryable. Make sure to put the annotation
in quotes, for handling spaces and stuff.</p>
<p>A example could be the author, a commit hash, or a branch.</p>
<pre><code class="language-bash">$ k annotate pod nginx  commit='866a8dc' branch='users/jloca/bug'
</code></pre>
<p>If we <code>describe</code> the object we will see our annotations there.</p>
<p>There are some well-known annotations, <code>pod-security.kubernetes.io/warn: baseline</code>
but that goes out of the scope of the course.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-application-deployment"><a class="header" href="#-application-deployment">üê¶ Application Deployment</a></h1>
<ol>
<li><a href="./ckad_prep_9.html">Deployments</a></li>
<li><a href="./ckad_prep_10.html">Helm</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deployments"><a class="header" href="#deployments">Deployments</a></h1>
<p>Managing a set of pods with the same config (called replicas) we want to make
sure we have the same config for these replicas.</p>
<p>We can scale up or down the number of replicas to fulfill our reqs. Updates to
a replica config can be easily rolled out automatically.</p>
<p>Under the hood, we say</p>
<ul>
<li><code>deployment</code>, "create 3 replicas"</li>
<li><code>ReplicaSet</code>, "maintain stable set of 3 pods"</li>
<li><code>pod</code>, "3 pods with the same definition"</li>
</ul>
<p>How do we create them imperatively:</p>
<pre><code class="language-bash">k create deployment my-deploy --image=nginx --replicas=3
</code></pre>
<p>The default <code>--replicas</code> is 1</p>
<p>The yaml would look like this:</p>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
</code></pre>
<p>Everything under the <code>spec.template</code> is the same as the attributes for the pod
spec.</p>
<p>The deployment internally uses label selector <code>spec.selector.matchLabels</code>, it
matches against <code>spec.template.metadata.labels</code>.</p>
<h2 id="rolling-out-changes"><a class="header" href="#rolling-out-changes">Rolling out changes.</a></h2>
<p>If you change the live object of the deployment, it will roll out the changes
of the <code>replicasets</code> by themselves.</p>
<p>It will keep a track of the changes, you can check it with:</p>
<pre><code class="language-bash">$ k rollout history deployment my-deploy
</code></pre>
<p>If we make a change to the deployment, for example assign a new image.</p>
<pre><code class="language-bas">k set image deployment my-deploy nginx=nginx:1.19.2
</code></pre>
<p>If you run the <code>k rollout history</code> command again, you will see the new
deployment.</p>
<p>If we want to come back to other versions, we can do</p>
<pre><code class="language-bash">k rollout undo deployment my-deploy --to-revision=1
</code></pre>
<p>You can annotate what changed on each revision</p>
<pre><code>k annotate deployment my-deploy kubernetes.io/change-cause="image updated to 1.17.1"
</code></pre>
<p>This will be displayed when listing the revisions.</p>
<h2 id="manually-scaling-a-deployment"><a class="header" href="#manually-scaling-a-deployment">Manually Scaling a Deployment</a></h2>
<pre><code class="language-bash">k scale deployment my-deploy --replicas=5
</code></pre>
<p>Or we can edit the live object of the deployment.</p>
<h2 id="autoscaling-a-deployment"><a class="header" href="#autoscaling-a-deployment">Autoscaling a Deployment</a></h2>
<p>The deployments scale automatically based on the metrics k8s is generating.</p>
<p>There are a couple of types of autoscalers (which are k8s objects):</p>
<ul>
<li>Horizontal Pod Autoscaler (HPA): standard feature of k8s that scales the
number of pod replicas based on cpu and memory thresholds.
(Relevant for the exam)</li>
<li>Vertical Pod Autoscaler (VPA): scales cpu and memory alloc for existing pods
based on historic metrics. Supported by a cloud provider as an add-on.</li>
</ul>
<p>Both of them use the metrics server. You need to install the component, and set
the resource requests and limits.</p>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
spec:
  scaleTargetRef: # the scaling target
    apiVersion: apps/v1
    kind: Deployment
    name: php-apache
  minReplicas: 3
  maxReplicas: 5
  metrics:
  - type: Resource # the thresholds
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
</code></pre>
<p>You can see them with <code>k get hpa</code></p>
<h2 id="deployment-strategies"><a class="header" href="#deployment-strategies">Deployment Strategies</a></h2>
<ul>
<li>
<p>ramped: we will touch one replica at a time and update the config needed.</p>
<ul>
<li>pros: leads to no downtime. We roll out the new version to all the replicas
overtime.</li>
<li>cons: make sure we do not introduce breaking changes</li>
</ul>
</li>
<li>
<p>recreate: terminate the old version and then create a new one with the new
config</p>
<ul>
<li>pros: good for dev envs, everything shutdowns at once and renewed at once</li>
<li>cons: can cause downtime</li>
</ul>
</li>
<li>
<p>blue/green: creates a new deployment with the new version, they run along
side each other, and once we are happy with the new one, we switch traffic.
(you need to set up two different deployments)</p>
<ul>
<li>pros: no downtime, traffic can be routed when ready</li>
<li>cons: resource duplication, config and network routing.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Special note on this one. When you have the two deployments, you'll need a
svc that is the one that actually exposes the app, then you can just change
the label selector there from blue to green (or viceversa) and k8s will do
the rest for you</p>
</blockquote>
<ul>
<li>canary: release a new version to a subset of users, then proceed to a full
roll out (useful for testing) (you need to set up two different deployments)
<ul>
<li>pros: new version released to subset of users.</li>
<li>cons: may require a load balancer for fine-grained dist</li>
</ul>
</li>
</ul>
<h3 id="how-do-we-implement-this"><a class="header" href="#how-do-we-implement-this">How do we implement this?</a></h3>
<p><code>under spec.strategy.type</code> we define the type we want. We can configure it
there</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="helm"><a class="header" href="#helm">Helm</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-application-observability--maintenance"><a class="header" href="#-application-observability--maintenance">üê§ Application Observability &amp; Maintenance</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-to-focus-on-each-topic"><a class="header" href="#what-to-focus-on-each-topic">What to focus on each topic.</a></h1>
<ul>
<li><a href="ckad_focus.html#containers">Containers</a></li>
<li><a href="ckad_focus.html#pods-and-namespaces">Pods and Namespaces</a></li>
<li><a href="ckad_focus.html#cronjob-and-jobs">Cronjob and jobs</a></li>
<li><a href="ckad_focus.html#volumes">Volumes</a></li>
<li><a href="ckad_focus.html#multi-container-pods">Multi-Container Pods</a></li>
<li><a href="ckad_focus.html#labels-and-annotations">Labels and Annotations</a></li>
<li><a href="ckad_focus.html#deployments">Deployments</a></li>
</ul>
<h2 id="containers"><a class="header" href="#containers">Containers</a></h2>
<ul>
<li>Practice with docker engine</li>
<li>Understand the most important instructions used in a dockerfile</li>
<li>Know hot to build a container image from a dockerfile</li>
<li>Learn how to save a container image to a file and how to load a container
from a file</li>
</ul>
<h2 id="pods-and-namespaces"><a class="header" href="#pods-and-namespaces">Pods and Namespaces</a></h2>
<ul>
<li>Practice command for creating, edit, inspecting and interacting with a Pod</li>
<li><code>k run</code> allows for fast creation of pod</li>
<li>Understand diff life cycles to be able to quickly diagnose error conditions</li>
</ul>
<h2 id="cronjob-and-jobs"><a class="header" href="#cronjob-and-jobs">Cronjob and jobs</a></h2>
<ul>
<li>The actual job is executed in pods.</li>
<li>Understand the different operational types (parallel, completion) for jobs
can be tricky.</li>
<li>Force yourself into setting up all possible scenarios and inspect their
runtime behaviour.</li>
<li>Know how to configure and inspect the retained job history.</li>
</ul>
<h2 id="volumes-1"><a class="header" href="#volumes-1">Volumes</a></h2>
<ul>
<li>Understand different use cases for wanting to use ephemeral or persistent.</li>
<li>Practice the most common volume types. (<code>emptyDir</code>, <code>hostPath</code>).</li>
<li>Go to the process of dynamic and static binding.
<ul>
<li>static, you need to create the pv</li>
<li>dynamic, automatically created the pv</li>
</ul>
</li>
</ul>
<h2 id="multi-container-pods-1"><a class="header" href="#multi-container-pods-1">Multi-Container Pods</a></h2>
<ul>
<li>The attributes that can be assigned to an <code>initContainers</code> section are the
same as the containers section</li>
<li>Design patterns (Sidecar, Ambassador, etc). When to use and how to implement.</li>
</ul>
<h2 id="labels-and-annotations-1"><a class="header" href="#labels-and-annotations-1">Labels and Annotations</a></h2>
<ul>
<li>Some primitives, Deployment, Service and Network Policy, use label selection
heavily.</li>
<li>Annotations are not made for querying, some reserved annotations may
influence runtime behaviour.</li>
</ul>
<h2 id="deployments-1"><a class="header" href="#deployments-1">Deployments</a></h2>
<ul>
<li>When creating a deployment make sure label selection match with the pod
template.</li>
<li>Practice how to scale the number of replicas manually <code>--replicas</code> or via
<code>hpa</code> for thresholds.</li>
<li>be aware of the <code>k rollout undo</code>.</li>
<li>know how to apply the deployment strategies.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-k8s-up-and-running"><a class="header" href="#-k8s-up-and-running">üêã k8s up and running</a></h1>
<blockquote>
<p>‚ö†Ô∏è These are notes taken from the book <a href="https://learning.oreilly.com/library/view/kubernetes-up-and/9781098110192"><em>Kubernetes Up and Running by Brendan
Burns, Joe Beda, and Kelsey Hightower O'Reilly</em></a>.
<strong>Please go read it and just use this as reference</strong>.</p>
</blockquote>
<ul>
<li><a href="./k8s_up_and_running_1.html">Introduction</a></li>
<li><a href="./k8s_up_and_running_2.html">Deploying a k8s cluster</a></li>
<li><a href="./k8s_up_and_running_3.html">Common <code>kubectl</code> commands</a></li>
<li><a href="./k8s_up_and_running_4.html">Pods</a></li>
<li><a href="./k8s_up_and_running_5.html">Labels</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<aside>
üí° K8s is an open source orchestrator for deploying containerized applications
</aside>
<p>It has become the standard API for building cloud native applications. It
provides the software needed for build and deploy, reliable, scalable
distributed systems.</p>
<p><strong>Distributed systems:</strong> Most services nowadays are delivered via the network,
they have different moving parts in different machines talking to each other
over the network via APIs.</p>
<p><strong>Reliable:</strong> Since we rely a lot on these distributed systems, they cannot
fail, even if some part of them crashes, they need to be kept up and running,
and be fault-tolerant</p>
<p><strong>Availability:</strong> They must still be available during maintenance, updates,
software rollouts and so on.</p>
<p><strong>Scalable:</strong> We live in a highly connected society, so these systems need to
be able to grow their capacity without radical redesign of the distributed
systems.</p>
<p>Most of the reasons people come to use containers and container orchestration
like k8s, can be boil down to 5 things:  <strong>velocity, scaling, abstracting your
infra, efficiency, cloud native ecosystem</strong></p>
<h2 id="development-velocity"><a class="header" href="#development-velocity">Development Velocity</a></h2>
<p>Today software is delivered via de network more quickly than ever, but velocity
is not just a matter of raw speed, people are more interested in a highly
reliable service, all users expect constant uptime, even as the software is
being updated.</p>
<p>Velocity is measures in term of the number of things you can ship while
maintaining a highly available service.</p>
<p>k8s give you the tools to to do this, the core concepts to enable this are:</p>
<ul>
<li>
<p><strong>Immutability</strong></p>
<p>Software used to be mutable (imperative), you installed <code>vim</code> using <code>dnf</code>
and then one day you would do <code>dnf update</code>  and it would add modifications
on top of the binary that you already have for <code>vim</code>. This is what we call
<em>mutable</em> software.</p>
<p>On the other hand, <em>immutable</em> software, you would not add on top of the
previous release, you would build the image from zero. Which is how
containers work. Basically when you want to update something in a
container, you do not go inside it and do <code>dnf update vim</code> you create a new
image with the version of vim you want, destroy the old one, and create a
container with the new one.</p>
<p>This makes rollbacks way easier, and it keeps tracks of what changed from
version to version.</p>
  <aside>
  üí° Imperatively change running containers (going into the container and
  update a package for example) is an anti-pattern, and should be avoided.
  </aside>
</li>
<li>
<p><strong>Declarative Configuration</strong></p>
<p>This is an extension of immutability but for the configuration. It
basically means that you have a file where you defined the ideal state of
your system. The idea of storing this files in source control is often
called ‚Äúinfrastructure as code‚Äù.</p>
<p>The combination of declarative state stored in a version control system and
the ability of k8s to make it  match the state makes rollback super easy.</p>
</li>
<li>
<p><strong>Self-Healing Systems</strong></p>
<p>K8s will continuously take action to make sure the state on the declarative
configuration is met. Say it has declared 3 replicas, then if you go and
create one extra, it will kill it, and if you were to destroy one, it would
create it.</p>
<p>This means that k8s will not only init your system but will guard it
against any failures that might destabilize it.</p>
</li>
</ul>
<h2 id="scaling-your-service-and-your-teams"><a class="header" href="#scaling-your-service-and-your-teams">Scaling Your Service and Your Teams</a></h2>
<p>K8s is great for scaling because of its decoupled architecture.</p>
<h3 id="decoupling"><a class="header" href="#decoupling">Decoupling</a></h3>
<p>In a decoupled architecture each components is separated from each other by
defined APIs and service loads</p>
<p>This basically means that we can isolate each service.</p>
<ul>
<li>The API provide a buffer between implementer and consumer.</li>
<li>Load balancing provide a buffer between running instances of each service.</li>
</ul>
<p>When we decouple the services, it makes it easier to scale, since each small
team can focus on a single <em>microservice</em></p>
<h3 id="scaling-for-applications-and-clusters"><a class="header" href="#scaling-for-applications-and-clusters">Scaling for Applications and Clusters</a></h3>
<p>Since your app is deployed in containers, which are immutable, and th
configuration o  is also declarative, scaling simply becomes a matter of
changing a number in a configuration file. Or you can even tell k8s to do that
for you.</p>
<p>Of course k8s will be limited to the resources you have, it will not create a
physical computer on demand. But k8s makes it easier to scale the cluster
itself as well.</p>
<p>Since a set of machines in a cluster are identical and the apps are decoupled
from the specifics of the machine by containers, scaling a cluster is just a
matter of provisioning the system and joining it to a cluster.</p>
<p>K8s can also come in handy when trying to forecast costs on growth and scaling.
Basically, if you have different apps that need to scale from many teams, you
can aggregate them all in a single k8s, and try to forecast the usage of the 3
apps together.</p>
<h3 id="scaling-development-teams"><a class="header" href="#scaling-development-teams">Scaling Development Teams</a></h3>
<p>Teams are ideal when using the two-pizza team when (6 to 8 people), larger
teams tend to have issues of hierarchy, poor visibility, infighting and so on.</p>
<p>K8s can help with that, since you can have multiple small teams working on
different microservices and  aggregate them all into a single k8s cluster.</p>
<p>K8s has different abstractions that make it easier to build decoupled
microservices.</p>
<ul>
<li><strong>pods</strong>: are groups of containers, can contain images developed by different
teams into a single deployable unit.</li>
<li><strong>k8s services</strong>: provide load balancing, naming and discovery to isolate the
microservices.</li>
<li><strong>namespaces</strong>: provide isolation and access control, so that each microservice
can control the degree to which other services interact with it.</li>
<li><strong>ingress</strong>: easy to use front end that can combine microservices into a single
API.</li>
</ul>
<h3 id="separation-of-concerns-for-consistency-and-scaling"><a class="header" href="#separation-of-concerns-for-consistency-and-scaling">Separation of Concerns for Consistency and Scaling</a></h3>
<p>K8s leads to greater consistency for the lower levels of the infrastructure.
Basically the devs need to only worry about their app meeting the SLA (service
level agreements) while the orchestration admin only need to worry about
reaching the SLA from their side.</p>
<h2 id="abstracting-you-infrastructure"><a class="header" href="#abstracting-you-infrastructure">Abstracting You Infrastructure</a></h2>
<p>When you build your app in terms of containers and deploy it via k8s APIs, you
make moving your app between environments super easy. It is simply a question
of sending the declarative config to a new cluster.</p>
<p>K8s make building deploying and managing your app truly portable across a wide
variety of environments</p>
<h2 id="efficiency"><a class="header" href="#efficiency">Efficiency</a></h2>
<p>Efficiency is measured by the ratio of the useful work performed by a machine.</p>
<p>K8s enables efficiency in multiple ways. Since developers do not need to use a
whole machine for himself/herself, but rather one container, multiple users can
share the same baremetal. Meaning less idle CPUs.</p>
<h2 id="cloud-native-ecosystem"><a class="header" href="#cloud-native-ecosystem">Cloud Native Ecosystem</a></h2>
<p>K8s is open source and has a huge community building a thousand things on top
of it. You can check the maturity of different projects in Cloud Native
Computing Foundation. The maturities are sandbox incubating and graduated,
going from less mature to most mature.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>Fundamentally k8s was design to give developers more velocity efficiency and
agility. Now that we have seen why to use it, lets see how to use it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deploying-a-k8s-cluster"><a class="header" href="#deploying-a-k8s-cluster">Deploying a k8s cluster</a></h1>
<p>You can use a cloud provider, deploying on  bare-metal quite hard, other good
alternatives.</p>
<p><a href="http://kind.sigs.k8s.io/docs/user/configuration/">http://kind.sigs.k8s.io</a>
that has a really cool logo, and works on using containers for the nodes.</p>
<p>Go check the pages of cloud providers on how to deploy it there since it will
change depending on the provider.</p>
<p>One thing to bare in mind is that in order to use <code>kubectl</code> with your cluster
you need a <code>~/.kube/config</code> file, probably your cloud provider will give that
to you.</p>
<p>Also you can go to <a href="/k8s_cheatsheet.html#describe-cluster">k8s cheatsheet (describe
cluster)</a> to see the basics commands on
describing a cluster.</p>
<p>I will  just cover some of the commands here, like</p>
<pre><code class="language-bash">k describe nodes &lt;node name&gt;
</code></pre>
<p>At the top you can see basic node info:</p>
<pre><code>Name:               kind-control-plane
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
</code></pre>
<p>We can see that it is linux on ARM</p>
<p>Next we can see info about the operation of the node</p>
<pre><code>Conditions:
Type             Status  LastHeartbeatTime  LastTransitionTime Reason                       Message
----             ------  -----------------  ------------------ ------                       -------
MemoryPressure   False   29 Apr 2024        29 Apr 2024        KubeletHasSufficientMemory   kubelet has sufficient memory available
DiskPressure     False   29 Apr 2024        29 Apr 2024        KubeletHasNoDiskPressure     kubelet has no disk pressure
PIDPressure      False   29 Apr 2024        29 Apr 2024        KubeletHasSufficientPID      kubelet has sufficient PID available
Ready            True    29 Apr 2024        29 Apr 2024        KubeletReady                 kubelet is posting ready status
</code></pre>
<p>Here we can see that the node is Ready, that it has sufficient memory, it has
no disk pressure, and that is has sufficient PID.</p>
<p>Then we see info about the capacity of the system.</p>
<pre><code>Capacity:
cpu:             1
memory:          1933908Ki
pods:            110
Allocatable:
cpu:             1
memory:          1933908Ki
pods:            110
</code></pre>
<p>Then info about software in the node like OS image, docker version all that.</p>
<pre><code>System Info:
# more stuff
Kernel Version:             6.5.6-200.fc38.aarch64
OS Image:                   Debian GNU/Linux 12 (bookworm)
Operating System:           linux
Architecture:               arm64
Container Runtime Version:  containerd://1.7.13
Kubelet Version:            v1.29.2
Kube-Proxy Version:         v1.29.2
</code></pre>
<p>Then info about the pods running on the node:</p>
<pre><code>Non-terminated Pods:          (9 in total)
Namespace                   Name                                          CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
---------                   ----                                          ------------  ----------  ---------------  -------------  ---
kube-system                 coredns-76f75df574-92286                      100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     23s
kube-system                 coredns-76f75df574-m2z2k                      100m (10%)    0 (0%)      70Mi (3%)        170Mi (9%)     23s
kube-system                 etcd-kind-control-plane                       100m (10%)    0 (0%)      100Mi (5%)       0 (0%)         39s
kube-system                 kindnet-qm29d                                 100m (10%)    100m (10%)  50Mi (2%)        50Mi (2%)      23s
kube-system                 kube-apiserver-kind-control-plane             250m (25%)    0 (0%)      0 (0%)           0 (0%)         39s
# more stuff
</code></pre>
<p>We can see that k8s tracks both <code>requests</code> and upper <code>limits</code> for resource for
each Pod. The difference is that resources requested by a pod are guaranteed to
be present in the node, while pod's limit is the max amount of given resource
that pod can consume</p>
<h2 id="cluster-components"><a class="header" href="#cluster-components">Cluster Components</a></h2>
<p>Many components that make up the k8s cluster are actually deployed using k8s
itself. All of them run in the kube-system namespace</p>
<ul>
<li>
<p>k8s proxy</p>
<p>It routes network traffic to load-balanced services in the k8s cluster. It
must be present on every node in the cluster</p>
<pre><code class="language-bash">% k get daemonSets --namespace=kube-system kube-proxy
</code></pre>
</li>
<li>
<p>k8s dns</p>
<p>provides naming and discover for the services that are defined in the
cluster</p>
<pre><code class="language-bash">% k get deployments --namespace=kube-system coredns
</code></pre>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-kubectl-commands"><a class="header" href="#common-kubectl-commands">Common <code>kubectl</code> commands</a></h1>
<blockquote>
<p>I will repeat the commands here and in the page: <a href="/k8s_cheatsheet.html">k8s
cheatsheet</a> but I will go a bit more into detail here.
I will also <code>alias k=kubectl</code></p>
</blockquote>
<p><code>kubectl</code> is the way you talk with k8s API. Here we will go over basic
<code>kubectl</code> commands.</p>
<h2 id="namespaces"><a class="header" href="#namespaces">Namespaces</a></h2>
<p>Namespaces are like folders that hold a set of objects. They are used to
organize the cluster.</p>
<p>By default the <code>kubectl</code> command interacts with the <code>default</code> namespace, but
you can specify which you want to use by <code>-n</code> or <code>--namespace=&lt;ns&gt;</code>.</p>
<p>You can also use <code>--all-namespaces</code> flag to refer to all the ns.</p>
<h2 id="contexts"><a class="header" href="#contexts">Contexts</a></h2>
<p>If you want to change the namespaces in a more <em>permanent</em> way, you can use
contexts. These get recorded in your <code>~/.kube/config</code> file. (That file also
stores how to find and auth to your cluster)</p>
<p>You can create a with a different default namespaces using</p>
<pre><code class="language-bash">% kubectl config set-context my-context --namespace=mystuff
</code></pre>
<p>We need to tell <code>kubectl</code> to start using it.</p>
<pre><code class="language-bash">% kubectl config use-context my-context
</code></pre>
<p>You can also use context to manage different clusters users for auth using
<code>--users</code> or <code>--cluster</code> flags with <code>set-context</code> read the man for more info</p>
<h2 id="viewing-k8s-api-objects"><a class="header" href="#viewing-k8s-api-objects">Viewing k8s API Objects</a></h2>
<p>Basically k8s is an API and kubectl is just an http client. To see the k8s
objects (everything represented by a RESTful resource) we use <code>k get &lt;resource name&gt;</code></p>
<p>By default it will throw to the STDOUT human readable stuff, but you can also
use <code>-o json</code> or <code>-o yaml</code> in case you want it in specific format.</p>
<p>Also when using <code>awk</code> you may want to use <code>--no-haders</code>.</p>
<p>You can also get multiple objects</p>
<pre><code class="language-bash">k get pods,services
</code></pre>
<p>To get more info on a particular object</p>
<pre><code class="language-bash">k describe &lt;resource name&gt; &lt;obj name&gt;
</code></pre>
<p>If you want to  see like a mini man page of an specific k8s object:</p>
<pre><code class="language-bash">% k explain pods
KIND:       Pod
VERSION:    v1

DESCRIPTION:
    Pod is a collection of containers that can run on a host. This resource is
    created by clients and scheduled onto hosts.

FIELDS:
  apiVersion	&lt;string&gt;
    APIVersion defines the versioned schema of this representation of an object.
    Servers should convert recognized schemas to the latest internal value, and
    may reject unrecognized values. More info:

</code></pre>
<p>Sometimes you want to continually observe the state of a k8s resource, like
when waiting for an app to restart of something you can use the <code>--watch</code> flag:</p>
<pre><code>k get pods -n kube-system --watch
</code></pre>
<h2 id="creating-updating-and-destroying-k8s-objects"><a class="header" href="#creating-updating-and-destroying-k8s-objects">Creating, updating and destroying k8s objects</a></h2>
<p>Objects in the k8s API are represented as JSON or YAML files. We can query the
server for those, or post them with an API request.</p>
<p>You use these JSON and YAML files to create, update or delete objects in your
k8s server.</p>
<p><strong>Create</strong> an object from <code>obj.yaml</code> file.</p>
<pre><code class="language-bash">% k apply -f obj.yaml
</code></pre>
<p>The yaml file will have the resource type of the object.</p>
<p>You can use the same command to <strong>update</strong> an object</p>
<pre><code class="language-bash">% k apply -f obj.yaml
</code></pre>
<p>If nothing change it will not do anything, it will exit successfully, good for
<code>for</code> loops. You can do <code>--dry-run</code> to print objects to the terminal without
actually sending them.</p>
<p>To do interactive edits you can use</p>
<pre><code class="language-bash">% k edit &lt;resource-name&gt; &lt;obj-name&gt;
# example k edit pod coredns-76f75df574-k97nj  -n kube-system
</code></pre>
<p>It will open the <code>yaml</code> in a text editor, wonce you save it will automatically
be uploaded back to the k8s cluster.</p>
<p>The <code>apply</code> command also has a history of the previous configurations
<code>edit-last-applied</code>, <code>set-last-applied</code> and <code>view-last-applied</code> for example:</p>
<pre><code class="language-bash">% k apply -f myobj.yaml view-last-applied
</code></pre>
<p>To delete you can simply run</p>
<pre><code class="language-bash">% k delete -f myobj.yaml
</code></pre>
<p>You can also delete an object without the file using</p>
<pre><code class="language-bash">% k delete &lt;resource-name&gt; &lt;obj-name&gt;
</code></pre>
<h2 id="labeling-and-annotating-objects"><a class="header" href="#labeling-and-annotating-objects">Labeling and Annotating Objects</a></h2>
<p>You can update the labels and annotations using <code>label</code> and <code>annotate</code> (who
would have thought).</p>
<p>For example to add the <code>color=red</code> label to the pod named <code>bar</code> you can run:</p>
<pre><code class="language-bash">k label pods bar color=red
</code></pre>
<p>You can not rewrite unless using <code>--overwrite</code> flag.</p>
<p>Finally you can remove a label by doing</p>
<pre><code class="language-bash">k labels pods bar color-
</code></pre>
<h2 id="debugging-commands"><a class="header" href="#debugging-commands">Debugging Commands</a></h2>
<p>You can check logs from a pod by:</p>
<pre><code class="language-bash">k logs &lt;pod-name&gt;
</code></pre>
<p>If you have multiple container in your pods you can choose which container to
view using the <code>-c</code> flag.</p>
<p>If you want to follow add <code>-f</code>.</p>
<p>You can also use the <code>exec</code> command to execute a command in a running
container.</p>
<pre><code class="language-bash">k exec -it &lt;pod-name&gt; -- bash
</code></pre>
<p>If you do not have bash or a shell in your container, you can <code>attach</code> to a
running process</p>
<pre><code class="language-bash">k attach -it &lt;pod-name&gt;
</code></pre>
<p>You can also copy files to and from a container using <code>cp</code></p>
<pre><code class="language-bash">k cp &lt;pod-name&gt;:/path/to/remote/file /path/to/local/file
</code></pre>
<p>This will copy a file from the container to your local machine.</p>
<p>You can also forward traffic from your local system to the pod</p>
<pre><code class="language-bash">k port-forward &lt;pod name&gt; 8080:80
</code></pre>
<p>Forwards traffic from the local machine on port 8080 to the remote container on
port 80</p>
<p>If you want to see the last 10 events in a namespace</p>
<pre><code>k get events
</code></pre>
<p>You can also stream events <code>--watch</code></p>
<p>Finally,  to check cluster resources being used</p>
<pre><code>k top nodes
</code></pre>
<p>or</p>
<pre><code>k top pods
</code></pre>
<p>These commands will only work if metrics servers are present, which they likely
are.</p>
<h2 id="cluster-management"><a class="header" href="#cluster-management">Cluster Management</a></h2>
<p>Cordon and drain a particular node:</p>
<ul>
<li><em>cordon</em>: prevent future pods form being scheduled onto that machine</li>
<li><em>drain</em>: remove any pods that are currently running on that machine.</li>
</ul>
<p>Useful for removing physical machine for repairs or upgrades. You would do <code>k cordon</code> and then <code>k drain</code> to safely remove the machine form the cluster.</p>
<p>Once the system is back online do <code>k uncordon</code> there is no <code>undrain</code> it will
naturally get back to normal.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pods-1"><a class="header" href="#pods-1">Pods</a></h1>
<p>K8s groups multiple containers into a single atomic unit called a <em>pod</em> (This
also goes with the docker theme, since a group of whales is a pod lol)</p>
<p>A pod is a collection of app containers and volumes running in the same
environment. Containers in a pod always land in the same machine.</p>
<p>Apps running in the same pod share, ip addresses and port, hostname, and can
communicate to each other using interprocess communication channels. Meaning
they share:</p>
<ul>
<li>network namespace</li>
<li>UTS namespace</li>
<li>IPC namespace</li>
</ul>
<h2 id="thinking-in-pods"><a class="header" href="#thinking-in-pods">Thinking in Pods</a></h2>
<p><em>What should go in a Pod?</em> To answer this question you go look at your
different containers and ask <em>"Will these containers work correctly if they
land on different machines?"</em> If no, then a pod is the correct way of grouping
them. If yes, you can use multiple pods.</p>
<p>An example, say you want to deploy a wordpress app with a mysql database. Would
you put them in the same pod? I already read the book so I know the answer is
no, but why?</p>
<p>The answer is no because both of those services do not need to scale together.
The wordpress app itself is stateless, so you can create more wordpress pods if
you are scaling. On the other hand a mysql database is much different to scale,
it can be trickier, and you are likely to increase the resources dedicated to a
single mysql pod.</p>
<h2 id="the-pod-manifest"><a class="header" href="#the-pod-manifest">The Pod Manifest</a></h2>
<p>Pods are describe in a <em>manifest</em> which is a text-file representation of the
k8s API object.</p>
<p>As you might remember from the fist chapter, k8s uses a <em>declarative
configuration</em>, which basically means that you tell k8s your ideal state of the
world and it will take action to ensure the state becomes a reality.</p>
<p>When you send a manifest to k8s, it will accept it and process it before
storing it in persistent storage <code>(etcd)</code>. The <em>scheduler</em> will find pods that
have not been assigned to a node, and will place the pods onto those nodes
depending on the resources and constrains you specified in your manifest. K8s
will try to ensure pods from the same app are in different machines for
reliability.</p>
<p>You can see the pods with</p>
<pre><code class="language-bash">k get pods
</code></pre>
<p>You can delete a pod with</p>
<pre><code class="language-bash">k delete pods/&lt;name&gt;
</code></pre>
<h3 id="creating-a-manifest"><a class="header" href="#creating-a-manifest">Creating a manifest</a></h3>
<p>Pod manifest should be treated in the same way a source code, adding comments
to help explain the pod to new team members and stuff like that.</p>
<p>The manifests include a couple of key fields and attributes,</p>
<ul>
<li><code>metadata</code>:
<ul>
<li><code>name</code>: a unique identifier for the deployment</li>
<li><code>namespace</code>: the Kubernetes namespace where the deployment will live</li>
<li><code>labels</code>: key-value pairs that can be used to filter and categorize objects</li>
</ul>
</li>
<li><code>spec</code>:
<ul>
<li><code>containers</code>:
<ul>
<li><code>name</code>: a unique identifier for the container</li>
<li><code>image</code>: the Docker image to use for this container</li>
<li><code>command</code>: the default command to run in the container</li>
<li><code>args</code>: any additional arguments to pass to the command</li>
<li><code>volumeMounts</code>: mounts for persistent storage or other files</li>
</ul>
</li>
<li>volumes:
<ul>
<li><code>name</code>: a unique identifier for the volume</li>
<li><code>persistentVolumeClaim</code>: claims a Persistent Volume resource</li>
</ul>
</li>
</ul>
</li>
<li><code>selectors</code>: used to filter which pods are included in this deployment</li>
</ul>
<p>Example</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2024-04-29T20:02:16Z"
  generateName: coredns-76f75df574-
  labels:
    k8s-app: kube-dns
    pod-template-hash: 76f75df574
  name: coredns-76f75df574-k97nj
  namespace: kube-system
  # more stuff
  uid: 4dd80223-de4c-49d7-b407-31908ae96b9e
spec:
  # more stuff
  containers:
  - args:
    - -conf
    - /etc/coredns/Corefile
    image: registry.k8s.io/coredns/coredns:v1.11.1
    imagePullPolicy: IfNotPresent
    # more stuff

    volumeMounts:
    - mountPath: /etc/coredns
      name: config-volume
      readOnly: true
    # more stuff

  volumes:
  - configMap:
      defaultMode: 420
      items:
      - key: Corefile
        path: Corefile
      name: coredns
      # more stuff

status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-04-29T20:02:19Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
  # more stuff
</code></pre>
<p>You can create a pod from them by using <code>k apply -f manifest.yaml</code> as seen in
previous sections.</p>
<h2 id="some-useful-commands"><a class="header" href="#some-useful-commands">Some Useful Commands</a></h2>
<pre><code class="language-bash"># get info
k get pods  # list pods
k describe pods &lt;podname&gt; # more info on the k8s object

# manipulate pods
k delete pods/&lt;podname&gt; # delete pod, all info associated to it will be deleted
k logs &lt;podname&gt; # check logs
k exec &lt;podname&gt; -- date # run date command inside pod
k exec -it &lt;podname&gt; -- bash # interactive tty
k cp # keep in mind that copying files into a container is an antipattern.
</code></pre>
<h2 id="health-checks"><a class="header" href="#health-checks">Health Checks</a></h2>
<p>When you are running an app in k8s, it is automatically kept alive by a process
health check. This ensure that the app is always running, if it is not it k8s
will restart it.</p>
<p>Sometimes, checking if the process is alive is not enough, maybe it was left
hanging or something like that. K8s has something to check application
<em>liveness</em> and other stuff for your app.</p>
<p>There are different kinds of probes here are some:</p>
<ul>
<li>
<p><strong>Liveness Probe</strong>
This will check app specific stuff, for example checking if http is
returning 200.</p>
<p>While the default response to a failed liveness is to restart you can
change what happened with <code>restartPolicy</code></p>
<p>Here is an example of a <code>livenessProbe</code></p>
<pre><code>spec:
  containers:
  - name: my-container
    image: my-image:latest
    livenessProbe:
      httpGet:
        path: /healthz
        port: 80
        scheme: HTTP
        initialDelaySeconds: 30
        timeoutSeconds: 5
</code></pre>
</li>
<li>
<p><strong>Readiness Probe</strong>
These probes check if an app is ready to serve user requests. Apps that
fail are removed from the load balancers</p>
</li>
<li>
<p><strong>Startup Probe</strong>
Enables you to poll slowly from a slow-starting container, while also
enabling  responsive liveness checks once the container has initialized</p>
</li>
</ul>
<h2 id="resource-management"><a class="header" href="#resource-management">Resource Management</a></h2>
<p>K8s allow you to increase the overall utilization of the machines that are in
the cluster.</p>
<p>Utilization is defined as the amount of resource actively being used divided by
the amount of a resource that has been purchased</p>
<p>Example, if you purchase a one-core machine, and your app uses one tenth of a
core, then your utilization is 10%</p>
<p>You can tell k8s the upper limit and lower limit of resources you want for an
specific container. Keep in mind that this is on a per-container basis, the
whole pod will the sum of the containers.</p>
<p>You can do this by setting up <code>resources</code> in the manifest. The lower limit is
<code>requests</code> and the upper limit is <code>limits</code>.</p>
<pre><code class="language-yaml">spec:
    containers:
    - image: blabla:latest
      name: jose
      resouces:
        cpu: "500m"
        memory: "128Mi"
      limit:
        cpu: "1000m"
        memory: "256Mi"
    # more stuff
</code></pre>
<h2 id="persisting-data-with-volumes"><a class="header" href="#persisting-data-with-volumes">Persisting Data with Volumes</a></h2>
<p>When a container restarts, any data in it will also be deleted. Which is good
since we do not want to leave around cruft.</p>
<p>We can still add volumes to our pods though, that will persist this deletion</p>
<p>In order to do this, you need to two things to the manifest <code>spec.volumes</code>,
which is an array of all volumes that the pod will need.</p>
<p>And the other is <code>volumeMount</code> which specify inside the container definition
the file system to use.</p>
<p>So basically one is like, what volumes will the whole pod use, and the other is
specific to each container.</p>
<pre><code class="language-yaml">spec:
  containers:
  - name: my-container
    image: busybox:latest
    volumeMounts:
    - name: my-filesystem
      mountPath: /mnt
      subPath: data
  volumes:
  - name: my-filesystem
    persistentVolumeClaim:
      claimName: my-pvc
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="labels-and-annotations-2"><a class="header" href="#labels-and-annotations-2">Labels and Annotations</a></h1>
<p>K8s apps can grow in size and complexity real quick. We can use <em>labels</em>
and <em>annotations</em> to help organize our k8s objects/resources as sets of
things that map how we think about the app. Making it a bit more human
accessible. Meaning we can group resources that make the most sense of the
application.</p>
<p>We have two tools that help with this.</p>
<ul>
<li><strong>Labels</strong>: key/value pairs, to attach identifying information  to the k8s
obj/resource. You will be able to query based on this.</li>
<li><strong>Annotations</strong>: set non-identifying information that libraries can leverage.
These are not meant for querying</li>
</ul>
<h2 id="labels-1"><a class="header" href="#labels-1">Labels</a></h2>
<p>Labels give identifying metadata for k8s objects. They are key/value pairs of
strings.</p>
<p>Keys are broken down into two parts</p>
<ul>
<li>Optional prefix name, separated by a slash.</li>
<li>Key name, it must start and end with alphanumeric chars.</li>
</ul>
<p>Some examples:</p>
<ul>
<li><code>acme.com/app-version</code> - <code>1.0.0</code></li>
<li><code>app.version</code> - <code>1.0.0</code></li>
</ul>
<h3 id="applying-labels"><a class="header" href="#applying-labels">Applying Labels</a></h3>
<p>You can do it when doing the <code>k run</code> command. (Doubt that is the way you are
using it but anyway):</p>
<pre><code class="language-bash">k run alpaca-test \
  --image=gcr.io/kuar-demo/kuard-amd64:green \
  --labels="ver=1,app=alpaca,env=test"
</code></pre>
<p>You can also add it to the manifest of the resource you are using:</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: example-pod
  labels:
    ver: "1"
    env: "test"
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
</code></pre>
<p>After the objects have been created, you can do <code>--show-labels</code></p>
<pre><code>k get deployments --show-labels
</code></pre>
<h3 id="modifying-labels"><a class="header" href="#modifying-labels">Modifying Labels</a></h3>
<p>You can update the labels on objects after creating them:</p>
<pre><code>k label deployemnts alpaca-test "canary=true"
</code></pre>
<p>Keep in mind that this will only update the label on the deployment itself, it
wont affect any objects created by the deployment.</p>
<p>In case you feel lazy you can replace <code>--show-labels</code> with <code>-L</code>.</p>
<pre><code>k get deployemnts -L canary
</code></pre>
<p>To remove a label you add a dash-suffix</p>
<pre><code>k label deployments alpaca-test "canary-"
</code></pre>
<h3 id="label-selectors"><a class="header" href="#label-selectors">Label Selectors</a></h3>
<p>Okay so, how do we query this stuff? Using boolean expressions</p>
<p>This will list only the pods that have ver label set to 2.</p>
<pre><code>k get pods --selector="ver=2"
</code></pre>
<p>You can get a bit more creative:</p>
<p>This is the AND operator:</p>
<pre><code>k get pods --selector="app=bandicoot,ver=2"
</code></pre>
<p>You can kind of do the OR by:</p>
<pre><code>k get pods --selector="app in (alpaca,bandicoot)"
</code></pre>
<p>You can also check if a label has been set by just using the key name:</p>
<pre><code>k get deployments --selector="canary"
</code></pre>
<p>Check if  key is not in <code>value1</code> or <code>value2</code>:</p>
<pre><code>k get pods --selector="key notin (value1, value2)"
</code></pre>
<p>You can combine them</p>
<pre><code>k get pods --selector="ver=2,!canary"
</code></pre>
<h3 id="labels-selector-in-manifests"><a class="header" href="#labels-selector-in-manifests">Labels Selector in Manifests</a></h3>
<p>Newer versions support doing something like this:</p>
<pre><code>selector:
  matchLabels:
    app: alpaca
  matchExpressions:
    - {key: ver, operator: In, values: [1, 2]}
</code></pre>
<h2 id="annotations"><a class="header" href="#annotations">Annotations</a></h2>
<p>This are only meant to assist tools and libraries, do not use them for queries.</p>
<p>If you are wondering if something should be a label or an annotations, add
information to an object as an annotation and promote it to a label if you find
yourself wanting to use it in a selector.</p>
<p>Usually annotations primary use is rolling deployments, they are used to track
rollout status and provide the information for a roll back if needed.</p>
<p>Annotations are defined in the <code>metadata</code> part of the  manifest:</p>
<pre><code>...
metadata:
  annotations:
    example.com/icon-url: "https://example.com/icon.png"
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="service-discovery"><a class="header" href="#service-discovery">Service Discovery</a></h1>
<p>K8s is a dynamic system. It has to manage placing pods on nodes, make sure they
are running and more stuff. Due to this nature k8s makes it easy to run a
lot of things, but it can be a bit hard to <em>find</em> these things.</p>
<h2 id="what-is-service-discovery"><a class="header" href="#what-is-service-discovery">What is Service Discovery?</a></h2>
<p>A service is a method for exposing a network application that is running in one
or more Pods in your cluster</p>
<p>Actually you use one type of service discover everyday, DNS, the thing that
helps you resolve hostnames to IPs. It works great for the internet, but falls
short in the k8s world.</p>
<p>Why? DNS caches a bunch of stuff, and in a k8s cluster pods are ephemeral, they
can be killed and come back up in seconds, so due to this cache we could be
pointing to something that is already dead.</p>
<p>While these pods that compose the backend may change, the frontend clients
should not need to be aware of that, nor should they need to keep track of the
of the backend themselves.</p>
<p>K8s has an object/resource specific to this issue.</p>
<h2 id="the-service-object"><a class="header" href="#the-service-object">The Service Object</a></h2>
<p>A Service is an object, it has a manifest and all that. Say you have a set of
pods that each listen on port 5000 and are labeled as <code>name=flask-app</code>. The
manifest would look something like this:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app.kubernetes.io/name: flask-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
</code></pre>
<p>K8s will assign the service a Cluster IP , and will be continuously scanning
for Pods that match the selector (the <code>flask-app</code> part). Then it will make the
updates to the set of <code>EndpointSlices</code> for the Service.</p>
<h2 id="using-the-type-nodeports"><a class="header" href="#using-the-type-nodeports">Using the type <code>NodePorts</code></a></h2>
<p>By using this type, in addition of a Cluster IP, the system picks a port on
every node in the cluster to forward traffic to the service.</p>
<p>Meaning you can connect to any node in the cluster, and reach an specific
service. You can use <code>NodePort</code> without knowing where any of the pods for that
service are running.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  type: NodePort &lt;--- here
  selector:
    app.kubernetes.io/name: MyApp
  ports:
    - port: 80
      # By default and for convenience, the `targetPort` is set to
      # the same value as the `port` field.
      targetPort: 80
      # Optional field
      # By default and for convenience, the Kubernetes control plane
      # will allocate a port from a range (default: 30000-32767)
      nodePort: 30007
</code></pre>
<p>Now each request that is send to the service will be randomly directed to one
of the pods that implements the service.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configmaps-and-secrets"><a class="header" href="#configmaps-and-secrets">ConfigMaps and Secrets</a></h1>
<p>A good practice is to make your container images reusable, making a general
purpose one that can be used across applications. But we might also need to add
some configuration to the image at runtime. Here is where ConfigMaps and
Secrets come into play.</p>
<ul>
<li><a href="k8s_up_and_running_13.html#configmaps">ConfigMaps</a>
<ul>
<li><a href="k8s_up_and_running_13.html#creating-configmaps">Creating ConfigMaps</a></li>
<li><a href="k8s_up_and_running_13.html#using-a-configmap">Using a ConfigMap</a></li>
</ul>
</li>
<li><a href="k8s_up_and_running_13.html#secrets">Secrets</a>
<ul>
<li><a href="k8s_up_and_running_13.html#creating-secrets">Creating Secrets</a></li>
<li><a href="k8s_up_and_running_13.html#consuming-secrets">Consuming Secrets</a>
<ul>
<li><a href="k8s_up_and_running_13.html#private-container-registries">Private Container Registries</a></li>
</ul>
</li>
<li><a href="k8s_up_and_running_13.html#naming-constrains">Naming Constrains</a></li>
<li><a href="k8s_up_and_running_13.html#managing-configmaps-and-secrets">Managing ConfigMaps and Secrets</a></li>
</ul>
</li>
</ul>
<h2 id="configmaps"><a class="header" href="#configmaps">ConfigMaps</a></h2>
<p>In a ConfigMap you can define env variables, command line arguments or even
small file systems for your containers. The <code>configmap</code> is combined with the Pod
right before it is run.</p>
<h3 id="creating-configmaps"><a class="header" href="#creating-configmaps">Creating ConfigMaps</a></h3>
<p>We can create a <code>configmap</code> out of a file. Say for example we have a file
called <code>config.txt</code>:</p>
<pre><code>parameter1 = value1
parameter2 = value2
</code></pre>
<p>You can create a <code>configmap</code> by doing:</p>
<pre><code class="language-bash">% k create configmap config --from-file=config.txt
</code></pre>
<p>Or you can create literally from the command line</p>
<pre><code class="language-bash">% k create configmap other-config --from-literal=some-param=some-value
</code></pre>
<p>Now you can list them</p>
<pre><code class="language-bash">% k get cm
NAME               DATA   AGE
config             1      35s
some-config        1      2s
</code></pre>
<p>And get them as <code>yaml</code>s</p>
<pre><code>% k get cm config -o yaml
apiVersion: v1
data:
  config.txt: |
    param1 = value1
    param2 = value2
kind: ConfigMap
metadata:
  creationTimestamp: "2024-06-11T00:58:10Z"
  name: config
  namespace: default
  resourceVersion: "2420"
  uid: 7df23db6-7d2c-4db4-9b22-5fecd4bb456e
</code></pre>
<p>At the end of the day, the <code>configmaps</code> are just some key/value pairs stores in
an object.</p>
<h3 id="using-a-configmap"><a class="header" href="#using-a-configmap">Using a ConfigMap</a></h3>
<p>There are 3 ways of using them:</p>
<ul>
<li>File system:
<ul>
<li>A ConfigMap can be mounted in a Pod. A file is created for each key, and
the content is their respective values</li>
</ul>
</li>
<li>Command-line Argument:
<ul>
<li>Creating command lines dynamically</li>
</ul>
</li>
<li>Environment Variable:
<ul>
<li>It can set the value of an environment variable</li>
</ul>
</li>
</ul>
<p>Let's see each as an example</p>
<ul>
<li>File System Volumes</li>
</ul>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata
  name: kuard-config
spec:
  containers:
    - name: test-container
      image: gcr.io/kuar-demo/kaurd-amd64:blue
      imagePullPolicy: Always
      command:
        - "/kuard"
    volumeMounts:
    # Mounting the ConfigMap as a set of files
    - name: config-volume # &lt;- HERE
      mountPath: /config
  volumes:
    - name: config-volume # &lt;- HERE
      configMap:
        name: config # &lt;- name of the cm we just created
  restartPolicy: Never
</code></pre>
<ul>
<li>Command-line Arguments</li>
</ul>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata
  name: kuard-config
spec:
  containers:
    - name: test-container
      image: gcr.io/kuar-demo/kaurd-amd64:blue
      imagePullPolicy: Always
      command:
        - "/kuard"
        - "$(EXTRA_PARAM)" &lt;- NOTE HERE
      env:
        - name: EXTRA_PARAM
            valueFrom:
            configMapKeyRef
            name: config # &lt;- name of the cm we just created
            key: param1
</code></pre>
<blockquote>
<p><strong>Note</strong> that k8s will perform the correct substitution with a special
<code>$(&lt;env-var-name&gt; )</code> syntax</p>
</blockquote>
<ul>
<li>Environment Variable:</li>
</ul>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata
  name: kuard-config
spec:
  containers:
    - name: test-container
      image: gcr.io/kuar-demo/kaurd-amd64:blue
      imagePullPolicy: Always
      command:
        - "/kuard"
      env:
        - name: ENV_PARAM
            valueFrom:
            configMapKeyRef
            name: config # &lt;- name of the cm we just created
            key: param2
</code></pre>
<h2 id="secrets"><a class="header" href="#secrets">Secrets</a></h2>
<p>This are pretty similar to ConfigMaps but they are intended for sensitive
information, for example, passwords, tokens, private keys, TLS certs.</p>
<p>This secrets are exposed to Pods via explicit declaration in the Pod manifest
and the k8s API.</p>
<blockquote>
<p>By default k8s stores secrets in plain text on <code>etcd</code> storage. If you have
super sensitive information there, and a lot of people with admin access,
might be worth encrypting it a bit more.</p>
</blockquote>
<h3 id="creating-secrets"><a class="header" href="#creating-secrets">Creating Secrets</a></h3>
<p>We can create a secret like any other resource</p>
<pre><code>% k create secret generic my-secret --from-file=some.key
</code></pre>
<p>Instead of <code>generic</code> -- depending on the secret -- we can use different types</p>
<p>From the manpage</p>
<pre><code class="language-bash">Available Commands:
  docker-registry   Create a secret for use with a Docker registry
  generic           Create a secret from a local file, directory, or literal value
  tls               Create a TLS secret
</code></pre>
<p>If we describe it</p>
<pre><code>% k describe secret my-secret
Name:         my-secret
Namespace:    default
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Type:  Opaque

Data
====
some.key:  1984 bytes
</code></pre>
<p>The Pods consume the secrets.</p>
<h3 id="consuming-secrets"><a class="header" href="#consuming-secrets">Consuming Secrets</a></h3>
<p>We can call the API directly, but more often we will access secrets from a
<em>Secrets Volume</em>. These volumes are created at pod creation time, and are
stored in <code>tmpfs</code> (meaning memory not disk).</p>
<p>Each secret is in a different file under the target mount point. So if we mount
the <code>my-secret</code> secret in the <code>/keys</code> directory, it would looks something like
<code>/keys/some.key</code>.</p>
<p>The Pod manifest would end up looking something like this:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata
  name: kuard-secret
spec:
  containers:
    - name: test-container
      image: gcr.io/kuar-demo/kaurd-amd64:blue
      imagePullPolicy: Always
    volumeMounts:
    - name: keys
      mountPath: /keys
      readOnly: true
  volumes:
    - name: keys
      secret:
        secretName: my-secret # &lt;- name of the secret we just created
</code></pre>
<h4 id="private-container-registries"><a class="header" href="#private-container-registries">Private Container Registries</a></h4>
<p>You can also create a secret for for use with a Docker registry. Instead of
<code>generic</code> you would use <code>docker-registry</code>, with <code>--docker-username</code>,
<code>--docker-password</code> and <code>--docker-email</code> and the manifest would look something
like this:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata
  name: kuard-secret
spec:
  containers:
    - name: test-container
      image: gcr.io/kuar-demo/kaurd-amd64:blue
      imagePullPolicy: Always
    volumeMounts:
    - name: keys
      mountPath: /keys
      readOnly: true
  imagePullSecrets:
  - name: my-image-pull-secrets-from-registry # &lt;- name of that secret
  volumes:
    - name: keys
      secret:
        secretName: my-secret
</code></pre>
<h3 id="naming-constrains"><a class="header" href="#naming-constrains">Naming Constrains</a></h3>
<p>Key names need to be valid variable names. Just use <em>normal</em> names and you will
be fine.</p>
<ul>
<li>
<p>valid</p>
<ul>
<li><code>.token</code></li>
<li><code>secret.token</code></li>
<li><code>config_file</code></li>
</ul>
</li>
<li>
<p>not valid</p>
<ul>
<li><code>token..key</code></li>
<li><code>auth token.key</code></li>
<li><code>_token</code></li>
</ul>
</li>
</ul>
<p>Just not use spaces, double dots and stuff like that.</p>
<h3 id="managing-configmaps-and-secrets"><a class="header" href="#managing-configmaps-and-secrets">Managing ConfigMaps and Secrets</a></h3>
<p>The usual stuff, <code>get</code>, <code>delete</code>, <code>create</code>. Just a note on creating:</p>
<ul>
<li><code>--from-file=&lt;filename&gt;</code>: keys in file will be keys in secret</li>
<li><code>--from-file=&lt;key&gt;=&lt;filename&gt;</code>: keys in file will be keys in secret
<ul>
<li>Instead of:
<pre><code>  Data
  ====
  &lt;filename&gt;:
  ----
  param1 = value1
  param2 = value2
</code></pre>
You would get
<pre><code>  Data
  ====
  &lt;key&gt;:
  ----
  param1 = value1
  param2 = value2
</code></pre>
</li>
</ul>
</li>
<li><code>--from-file=&lt;directory&gt;</code>: loads all files in a directory</li>
</ul>
<p>Also you can recreate and update like:</p>
<pre><code>kubectl create secret generic kuard-tls \
  --from-file=kuard.crt --from-file=kuard.key \
  --dry-run -o yaml | kubectl replace -f -
</code></pre>
<p>Neat trick from the book <a href="https://learning.oreilly.com/library/view/kubernetes-up-and/9781098110192"><em>Kubernetes Up and Running by Brendan Burns, Joe
Beda, and Kelsey Hightower
O'Reilly</em></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-k8s-cheatsheet"><a class="header" href="#-k8s-cheatsheet">üìù k8s cheatsheet</a></h1>
<p>Some useful commands</p>
<blockquote>
<p><em>using kind?</em></p>
<p>in you mac? with podman?</p>
<pre><code class="language-bash">podman machine init
podman machine start;
export KIND_EXPERIMENTAL_PROVIDER=podman;
kind create cluster
</code></pre>
</blockquote>
<h1 id="describe-cluster"><a class="header" href="#describe-cluster">Describe Cluster</a></h1>
<ul>
<li>
<p>Check version</p>
<pre><code class="language-bash">% k version  # what do you think it does? :)
*Client Version: v1.28.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2*
</code></pre>
</li>
<li>
<p>Check cluster status</p>
<pre><code class="language-bash">% k get componentstatuses # will be deprectated
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE   ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-0               Healthy   ok
</code></pre>
<p>or talk directly to the endpoint</p>
<pre><code class="language-bash">% k get --raw='/readyz?verbose'
[+]ping ok
[+]log ok
[+]etcd ok
[+]etcd-readiness ok
[+]informer-sync ok
 # more messages
 readyz check passed
</code></pre>
</li>
<li>
<p>List k8s nodes</p>
<pre><code class="language-bash">% k get nodes
NAME                 STATUS     ROLES           AGE   VERSION
kind-control-plane   Ready   control-plane   13s   v1.29.2
node01               Ready   &lt;none&gt;          13s   v1.29.2
</code></pre>
<p>In k8s nodes are separated into <code>control-panel</code> nodes, like the API server,
scheduler, etc. which manage the cluster, and <code>worker</code> nodes where your
containers will run.</p>
</li>
<li>
<p>Get more information about a specific node (prints bunch of info)</p>
<pre><code class="language-bash">% k describe nodes kind-control-plane
</code></pre>
<p>more info on the ouput
<a href="/k8s_up_and_running.html#deploying-a-k8s-cluster">here</a></p>
</li>
<li>
<p>See the proxies if they are under the API object named DaemonSet</p>
<pre><code class="language-bash">% k get daemonSets --namespace=kube-system kube-proxy
</code></pre>
</li>
<li>
<p>See DNS k8s deployment</p>
<pre><code class="language-bash">% k get deployments --namespace=kube-system coredns
</code></pre>
</li>
<li>
<p>Wait for nodes to be ready</p>
<pre><code class="language-bash">% k wait --for=condition=Ready nodes --all
node/node1 condition met
node/node2 condition met
...
</code></pre>
</li>
</ul>
<h1 id="manage-your-context"><a class="header" href="#manage-your-context">Manage your context</a></h1>
<ul>
<li>
<p>Change namespace for current context</p>
<pre><code class="language-bash">% kubectl config set-context --current --namespace=&lt;some ns&gt;
</code></pre>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-helm"><a class="header" href="#-helm">‚éà helm</a></h1>
<blockquote>
<p>‚ö†Ô∏è These are notes taken from the book <a href="https://learning.oreilly.com/library/view/learning-helm/9781492083641/ch02.html#idm46126000033640"><em>Learning Helm by Matt Butcher, Matt
Farina and Josh Dolitsky on
O'Reilly</em></a>
<strong>Please go read it and just use this as reference</strong>.</p>
</blockquote>
<ul>
<li><a href="helm.html#introduction">Introduction</a>
<ul>
<li><a href="helm.html#context-for-helm-containers--k8s">Context for Helm (containers &amp; k8s)</a>
<ul>
<li><a href="helm.html#containers">Containers</a></li>
<li><a href="helm.html#kubernetes-or-k8s-like-the-cool-kids-call-it">Kubernetes (or k8s like the cool kids call it)</a></li>
<li><a href="helm.html#pods">Pods</a></li>
<li><a href="helm.html#configmaps"><code>ConfigMaps</code></a></li>
<li><a href="helm.html#deployments">Deployments</a></li>
<li><a href="helm.html#service">Service</a></li>
</ul>
</li>
<li><a href="helm.html#helms-goal">Helm's Goal</a></li>
<li><a href="helm.html#helm-architecture">Helm Architecture</a>
<ul>
<li><a href="helm.html#k8s-resourceobject">K8s Resource/Object</a></li>
<li><a href="helm.html#charts">Charts</a></li>
<li><a href="helm.html#resources-installations-and-releases">Resources, Installations and Releases</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="helm.html#using-helm">Using Helm</a>
<ul>
<li><a href="helm.html#adding-a-chart-repo">Adding a Chart Repo</a></li>
<li><a href="helm.html#installing-a-package">Installing a package</a></li>
<li><a href="helm.html#listing-your-installations">Listing your Installations</a></li>
<li><a href="helm.html#upgrading-an-installation">Upgrading an Installation</a></li>
<li><a href="helm.html#configuration-values">Configuration Values</a></li>
<li><a href="helm.html#uninstalling-charts">Uninstalling charts</a></li>
</ul>
</li>
</ul>
<h1 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h1>
<p>Helm is the package manager for k8s. Let us do a super quick dive into what k8s
is an all that just to give the context necessary to understand helm.</p>
<h2 id="context-for-helm-containers--k8s"><a class="header" href="#context-for-helm-containers--k8s">Context for Helm (containers &amp; k8s)</a></h2>
<p>Sometime ago someone thought of a new way of making apps, instead of them being
a big monolithic service, we could split everything into small discrete
standalone services. Then we could join those services using API over the
network and build the application that way. That is how microservices were
born.</p>
<h3 id="containers-1"><a class="header" href="#containers-1">Containers</a></h3>
<p>To help with this the concept of containers was introduced, it is different of
a VM because the VM runs an entire OS on on a host machine. On the other hand,
a container has its own file system, but it uses the same OS kernel as the
host.</p>
<p>A container is a program together with its dependencies and environment, they
are packaged together into a <em>container image</em> which can be build based on a
file where you specify the packages you want to run, and how to set the
environments. The cool part is that all those instructions are not compiled
into a binary or anything, but they are packaged into discrete layers.</p>
<p>So if a host has an image with five layers, and there is another host that
needs the same image, it will just fetch the layers it does not already have.</p>
<p>Say you have three images using <code>fedora-minimal:37</code>, well it would reuse that
layer on all those three.</p>
<p>Those images are stored in a <em>registry</em>, the registry tells hosts which layers
compose an image. So the host can only download the layers it need from the
registry.</p>
<p>A registry identifies an image by three things:</p>
<ul>
<li>name: basically a string <code>fedora</code> or <code>fedora-minimal</code></li>
<li>tag: usually the version <code>latest</code> or <code>v1</code></li>
<li>digest: a hash of the image, since the tags are mutable.</li>
</ul>
<p>They look like <code>name:tag@digest</code>.</p>
<h3 id="kubernetes-or-k8s-like-the-cool-kids-call-it"><a class="header" href="#kubernetes-or-k8s-like-the-cool-kids-call-it">Kubernetes (or k8s like the cool kids call it)</a></h3>
<p>So with all these container stuff, some questions begin to arise:</p>
<ul>
<li>How do we best execute lots of containers?</li>
<li>How can they work together?</li>
<li>How do we manage memory, cpu, network and storage?</li>
</ul>
<p>Well a bunch of companies tried to create this orchestration of containers
technology to answer those questions, at the end as per 2024 seems like Google
won, and we now all use ‚õµÔ∏è K8s.(which is greek for ship's capitan or something
like that)</p>
<p>K8s won because it introduced two concepts that people really liked.</p>
<ul>
<li>
<p><strong>Declarative infrastructure</strong>
Basically you tell k8s what your desired state of the cluster is, and it
will work to make that happen.</p>
</li>
<li>
<p><strong>Reconciliation loop</strong>
How does k8s work behinds the scenes to reach the declarative configuration
we set? Using a reconciliation loop.</p>
<p>In a reconciliation loop, the scheduler says: "Here is what the user wrote
as his/her desired state. Here is the current state. They are not the same,
lets reconcile them."</p>
<p>Say you specified storage, and the scheduler sees that we do not have
storage yet, it will create units of storage and attach them to your
containers.</p>
</li>
</ul>
<h3 id="pods-2"><a class="header" href="#pods-2">Pods</a></h3>
<p>We do not deal directly with containers when setting up our k8s cluster.
We use a pods. A pod which is basically a group of containers. These are
defined in a manifest (<code>yaml</code> or <code>json</code>, but most people use <code>yaml</code>)</p>
<pre><code class="language-yaml">apiVersion: v1 # we can see that this will be a v1 Pod
kind: Pod
metadata:
    name: example-pod
spec:
    containers:
    - image: "fedora-minimal:latest"
    - name: example-fedora
</code></pre>
<p>A Pod can have 1 or more containers. The containers that help preconfigurate
stuff for the main one, are called <em>init containers</em>.</p>
<p>The ones that run alongside the main container are called <em>sidecar containers</em></p>
<h3 id="configmaps-1"><a class="header" href="#configmaps-1"><code>ConfigMaps</code></a></h3>
<p>Basically in a pod you describe the configuration the containers need, like
network ports files system mount points. You can store configuration
information for k8s in <code>ConfigMaps</code> and password and stuff like that in
<code>Secret</code>.</p>
<p>Here is an example:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
    name: configuration-data
data: # inside here we will declare aribitrary key/value stuff
    backgroundColor: blue
    title: Learning Helm
</code></pre>
<p>For <code>Secret</code> is pretty much the same as for <code>ConfigMaps</code> but the values in data
must be Base64 encoded.</p>
<p>Pods then can be linked to the ConfigMaps like this:</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
    name: example-pod
spec:
    volumes:
    # note that this is not the metadata name you used in the ConfigMap
    - name: my-configuration
      configMap:
        name: configuration-data # same name as in metadata of ConfigMap
    containers:
    - image: "fedora-minimal:latest"
      name: example-fedora
      env:
        - name: TITLE # the env variable will be title
          valueFrom:
            configMapKeyRef:
                name: configuration-data # name for the volume
                key: title # key in the actual ConfigMap
</code></pre>
<h3 id="deployments-2"><a class="header" href="#deployments-2">Deployments</a></h3>
<p>Pretty cool stuff, but we might not just one to run one instance of our
container, therefore we can use something called <code>Deployments</code>.</p>
<p>A <code>Deployment</code> describe an application as a collection of identical pods,we can
tell k8s to create our app with a single pod and scale it up to five pods.</p>
<pre><code class="language-yaml">apiVersion: apps/v1 # apps/v1 Deployment
kind: Deployment
metadata:
    name: example-deployment
    labels:
        app: my-deployment
spec:
    replicas: 3 # we want three replicas of the following template
    selector:
        matchLabels:
            app: my-deployment
    template:
        metadata:
            labels:
                app: my-deployment
        spec:
           containers :
            -image: "fedora-minimal"
             name: "example-fedora"
</code></pre>
<h3 id="service"><a class="header" href="#service">Service</a></h3>
<p>A <code>Service</code> is a persistent network resource, that persists even if the pod or
pods attached to it go away.</p>
<pre><code class="language-yaml">apiVersion: v1
kind: Service
metadata:
    name: example-service
spec:
    selector:
      app: my-deployment
    ports:
      -  protocol: TCP
         port: 80
         targetPort: 8080
</code></pre>
<p>Here we define a service for the pods with the <code>app: my-deployment</code>, telling
that traffic port 80 of this <code>Service</code> will be routed to 8080.</p>
<h2 id="helms-goal"><a class="header" href="#helms-goal">Helm's Goal</a></h2>
<p>So we have seen the building block of K8s, say you want to deploy a WordPress
app, you would need a <code>Deployment</code> for the containers, then a <code>ConfigMap</code> and
<code>Secret</code> for the password, maybe some <code>Service</code> objects and so on. That sounds
like a lot of <code>yaml</code>.</p>
<p>The core idea of Helm  is that all those objects can be packaged to be
<code>installed</code>, <code>updated</code> and <code>deleted</code> together.</p>
<p>Basically helm is the package manger of kuberentes.  Helm will allow you to
spin up all the k8s objects necessary for an app by just using a few commands.</p>
<p>Here are some of the things that helm can do:</p>
<ul>
<li>Provide package repos (similar to <code>dnf</code> or <code>apt</code>).</li>
<li>Familiar install, upgrade, delete commands.</li>
<li>Helm has a method for configuring the packages before installing them.</li>
<li>Helm can also let you know what already is installed.</li>
</ul>
<p>You can also limit the installation of packages to a specific namespace, so you
can install the same package in different namespaces in the same k8s cluster.
(<a href="/k8s_up_and_running.html#namespaces">What is a namespace?</a>)</p>
<p>Helm also provides <strong>reusability</strong>, it uses charts for this. A chart provides a
pattern for producing the same k8s manifests. But the cool part is that you can
also add more configuration to those charts.</p>
<p>Helm provides patterns for storing the initial configuration plus the changes
you did. Helm encourages k8s users to package their <code>yaml</code> into charts so that
these descriptors can be reused.</p>
<p>One last thing, keep in mind that helm is not a configuration tool, it helps
but it there are software specialized on that like ansible, puppet or chef.</p>
<h2 id="helm-architecture"><a class="header" href="#helm-architecture">Helm Architecture</a></h2>
<p>Here are the main components that helm uses.</p>
<h3 id="k8s-resourceobject"><a class="header" href="#k8s-resourceobject">K8s Resource/Object</a></h3>
<p>These are the <code>Pods</code>, <code>ConfigMap</code>, <code>Deployment</code>, we have seen throughout the
chapter. K8s has a lot of these objects, you can even define custom ones using
custom resource definition (CRD).</p>
<p>All the resources share some elements</p>
<pre><code class="language-yaml">apiVersion: apps/v1 # api and version of the resource
kind: Deployment # resource type
metadata: # top-level data on the resource/object
    name: example-deployment # req for all objects
    labels: # used for creating query-able handles
        some-name: some-value
    annotations: # authors to attach their own keys and values
        some-name: some-value
</code></pre>
<h3 id="charts"><a class="header" href="#charts">Charts</a></h3>
<p>A package is called a chart. The idea es that k8s meaning captian, helm being
the steering mechanism of the ship. The chart plots the way k8s apps should be
installed.</p>
<p>A Chart is a set of files and directories that describe how to install the
different k8s resource/objects</p>
<p>A chart contains</p>
<ul>
<li><code>Chart.yaml</code>: describes the chart (name, description, authors)</li>
<li><code>templates</code> directory: Inside all the k8s manifests  potentially annotated
with templating directives</li>
<li><code>values.yaml</code>  file that provides the default configuration. You can override
during installation.</li>
</ul>
<p>These are the basic stuff for an unpacked chart, a packed chart is just a tar
ball with all this inside.</p>
<h3 id="resources-installations-and-releases"><a class="header" href="#resources-installations-and-releases">Resources, Installations and Releases</a></h3>
<p>When a helm chart is installed:</p>
<ol>
<li>helm reads the charts (will download if necessary)</li>
<li>It sends the values into the templates generating the k8s manifests</li>
<li>The manifests are sent to k8s</li>
<li>K8s creates the requested resources inside the cluster</li>
</ol>
<p>One last concept <em>release</em>. A release is created each time we use helm to
modify the installation</p>
<h1 id="using-helm"><a class="header" href="#using-helm">Using Helm</a></h1>
<p>Helm is a cli, you can install it with your favorite package manger or  build
it from source it is written in golang.</p>
<p>You can check the version by</p>
<pre><code>helm version
</code></pre>
<p>Helm will use the same KUBECONFIG file you have configured for <code>kubectl</code>, it
will look in the same places, though you can specify a path for one.</p>
<p>The most common workflow is:</p>
<ol>
<li>Add a chart repo</li>
<li>Find a chart to install</li>
<li>Install a Helm  chart</li>
<li>See the list of what is installed</li>
<li>Upgrade your installation</li>
<li>Delete your installation</li>
</ol>
<h2 id="adding-a-chart-repo"><a class="header" href="#adding-a-chart-repo">Adding a Chart Repo</a></h2>
<p>A Helm Chart is an individual package that can be installed into your k8s
cluster. You can find then  at chart repositories.</p>
<p>You can find popular repositories in <a href="https://artifacthub.io">the artifact hub</a></p>
<p>By default <code>helm</code> does not have any repo added, so you need to look for one
there.</p>
<p>Bitnamis's official Helm charts are one of the best well-curated charts repos.
(Some Bitnami devs are among the core contributors who design the helm repo
system)</p>
<p>To add a repo you do <code>helm repo add</code> so:</p>
<pre><code class="language-bash">% helm repo add bitnami https://charts.bitnami.com/bitnami
"bitnami" has been added to your repositories
</code></pre>
<p>Now if you do</p>
<pre><code class="language-bash">% helm repo list
NAME    URL
bitnami https://charts.bitnami.com/bitnami
</code></pre>
<p>You will see it there. After that we can look for specific charts.</p>
<pre><code class="language-bash">% helm search repo drupal
NAME            CHART VERSION   APP VERSION     DESCRIPTION
bitnami/drupal  18.0.2          10.2.5          Drupal is one of the most versatile open source...
</code></pre>
<p>You can also search label and descriptions</p>
<pre><code class="language-bash">% helm search repo content
NAME                    CHART VERSION   APP VERSION     DESCRIPTION
bitnami/drupal          18.0.2          10.2.5          Drupal is one of the most versatile open source...
bitnami/harbor          21.1.2          2.10.2          Harbor is an open source trusted cloud-native r...
bitnami/nginx           16.0.6          1.25.5          NGINX Open Source is a web server that can be a...
bitnami/owncloud        12.2.11         10.11.0         DEPRECATED ownCloud is an open source content c...
bitnami/wordpress       22.2.2          6.5.2           WordPress is the world's most popular blogging ...
</code></pre>
<p>The chart version is the version of well, the chart. On the other hand the app
version is the version of the software it would install.</p>
<h2 id="installing-a-package"><a class="header" href="#installing-a-package">Installing a package</a></h2>
<pre><code class="language-bash">% helm install mysite bitnami/drupal
NAME: mysite
LAST DEPLOYED: Wed May  1 16:40:16 2024
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
# more text
</code></pre>
<p>Typical stuff, just a few things to keep in mind.</p>
<ul>
<li>
<p>Difference between an installation and a chart.</p>
<p>An installation of a chart is a specific instance of the chart
One chart may have many installations</p>
</li>
<li>
<p>You can repeat instance names (<code>mysite</code>), but it must be on different
namespaces.</p>
</li>
</ul>
<p>You can set values specific to your installation, you can set them directly
from the command line with <code>--set</code>  for example. (this works with both set
<code>install</code> and <code>upgrade</code>)</p>
<pre><code class="language-bash">% helm install mysite bitnami/drupal --set drupalUsername=admin
</code></pre>
<p>You can also have them in a <code>yaml</code> file, which is the recommended approach.</p>
<pre><code class="language-bash">% helm upgrade mysite bitnami/drupal --values values.yaml
</code></pre>
<p>For example <code>values.yaml</code> would look like this:</p>
<pre><code class="language-yaml">drupalUsername: admin
drupalEmail: admin@example.com
mariadb:
    db:
        name: "my-database"
</code></pre>
<h2 id="listing-your-installations"><a class="header" href="#listing-your-installations">Listing your Installations</a></h2>
<pre><code class="language-bash">% helm list
NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
mysite  default         1               2024-05-01 16:40:16.50636 -0600 CST     deployed        drupal-18.0.2   10.2.5
</code></pre>
<p>Not much to say here, does what expected.</p>
<h2 id="upgrading-an-installation"><a class="header" href="#upgrading-an-installation">Upgrading an Installation</a></h2>
<p>So there are two types of changes:</p>
<ul>
<li>upgrade version of the chart</li>
<li>upgrade configuration of the chart</li>
</ul>
<p>Every time we perform an upgrade we are doing a new release of the same
installation.</p>
<p>Helm will attempt to to alter only the bare minimum, so if you only changes one
simple configuration variable, it will not like restart everything and all
that.</p>
<p>To restart stuff just use <code>kubectl</code>.</p>
<p>To update your chart with a new version you can</p>
<pre><code class="language-bash">% helm repo update
% helm upgrade mysite bitnami/drupal
</code></pre>
<h2 id="configuration-values"><a class="header" href="#configuration-values">Configuration Values</a></h2>
<p>If you do this:</p>
<pre><code class="language-bash">% helm install mysite bitnami/drupal --values values.yaml
% helm upgrade mysite bitnami/drupal
</code></pre>
<p>Chances are you lost your values, so it is good to always send the <code>yaml</code></p>
<pre><code class="language-bash">% helm install mysite bitnami/drupal --values values.yaml
% helm upgrade mysite bitnami/drupal --values values.yaml
</code></pre>
<p>You can use <code>helm get values mysite</code> to see the values sent on the last install
or upgrade.</p>
<p>You could also use:</p>
<pre><code class="language-bash">% helm upgrade mysite bitnami/drupal --reuse-values
</code></pre>
<p>But it is not recommended</p>
<h2 id="uninstalling-charts"><a class="header" href="#uninstalling-charts">Uninstalling charts</a></h2>
<p>Not much to say here</p>
<pre><code class="language-bash">% helm uninstall mysite
</code></pre>
<p>Works as you would expect, if you would do</p>
<pre><code>% helm list
</code></pre>
<p>You will not see it there.</p>
<p>Lastly, you can see a special record that contain release information.</p>
<pre><code class="language-bash">% k get secret
</code></pre>
<p>Helm stores there the info.</p>
<p>If you uninstall you loose the history, so be careful. You could <code>helm uninstall --keep-history</code>. Good if you plan on doing <code>helm rollback</code>.</p>
<p>That is pretty much the basics on helm.</p>
<div style="break-before: page; page-break-before: always;"></div><p><a href="https://www.youtube.com/watch?v=sIVGsQgMHIo&amp;t=44s">source</a></p>
<h1 id="what-is-fluentd"><a class="header" href="#what-is-fluentd">What is Fluentd</a></h1>
<p>It is a event/data collection tool. We can have multiple applications with tons
of different logs formats. Fluentd tries to unify them.</p>
<p>It is extensible, the core program is small, and does only the main stuff.</p>
<ul>
<li>Divide &amp; Conquer</li>
<li>Buffering &amp; Retries</li>
<li>Error Handling</li>
<li>Message Routing</li>
<li>Parallelism</li>
</ul>
<p>It delegate the rest to the users via plugins, reading data, parsing data,
buffering data, write data.</p>
<p>It is reliable, it is important to not loose data. Fluentd tries to move the
data in small pieces and checks if the data passed successfully if not it
retries.</p>
<p>Fluentd can tag the data and route it according to the label.</p>
<h1 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h1>
<h3 id="simple-forwarding"><a class="header" href="#simple-forwarding">Simple Forwarding</a></h3>
<p>You have some simple files that and logs from a port and
want to forward them to mongodb. Here is a simple configuration example.</p>
<p>logs from a file</p>
<pre><code>&lt;source&gt;
    type tail
    path /var/log/httpd.log
    format apache2
    tag web.access
&lt;/source&gt;
</code></pre>
<p>logs from client libraries</p>
<pre><code>&lt;source&gt;
    type forward
    port 24224
&lt;/source&gt;
</code></pre>
<p>store logs to ES and HDFS</p>
<pre><code>&lt;source backend.* &gt;
    type mongo
    database fluent
    collection test
&lt;/source&gt;
</code></pre>
<h1 id="lambda-architecture"><a class="header" href="#lambda-architecture">Lambda Architecture</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="-elastic-stack-elk"><a class="header" href="#-elastic-stack-elk">üìà Elastic Stack (ELK)</a></h1>
<h1 id="table-of-contents-1"><a class="header" href="#table-of-contents-1">Table of contents</a></h1>
<ul>
<li><a href="elk_stack.html#components">Components</a></li>
<li><a href="elk_stack.html#logstash">Logstash</a>
<ul>
<li><a href="elk_stack.html#logstash-plugins">Logstash Plugins</a></li>
<li><a href="elk_stack.html#filters">Filters</a></li>
<li><a href="elk_stack.html#grokconstructor">GrokConstructor</a></li>
</ul>
</li>
<li><a href="elk_stack.html#beats">Beats</a></li>
</ul>
<p>ELK is great for <strong>Centralized Logging</strong>, this enable us to not waste time
trying to find where the issues are, we have all in one place. We also can</p>
<p>Kibana is the visualization of the ELK stack, you can visualize the data on
real time.</p>
<h1 id="components"><a class="header" href="#components">Components</a></h1>
<p>It has several open source add-ons, but the main ones are these:</p>
<ul>
<li><strong>Beats</strong>:
<ul>
<li>Light weight way of getting data into the ELK stack.</li>
<li>Single purpose tools.</li>
</ul>
</li>
<li><strong>Logstash</strong>:
<ul>
<li>Transform data as it comes into structured data that will be stored.</li>
<li>Very resource intensive</li>
<li>Example: is like cutting carrots ü•ï as you get from the store and saving
them to the fridge, instead of cutting them until you are about to cook</li>
</ul>
</li>
<li><strong>Elasticsearch</strong>:
<ul>
<li>The part of the stack that stores the data itself</li>
<li>Usually deployed by a cluster, it has redundant copies so it can work if
something fails</li>
</ul>
</li>
<li><strong>Kibana</strong>:
<ul>
<li>Web front end for the ELK stack</li>
<li>Quick bird‚Äôs eye view across your infra</li>
</ul>
</li>
</ul>
<h1 id="logstash"><a class="header" href="#logstash">Logstash</a></h1>
<p>Three block  of code in config</p>
<ul>
<li>Input: get data in</li>
<li>Output put data somewhere, usually elasticsearch</li>
<li>Filter block: where data is transformed and relocated, where we can parse
lines.</li>
</ul>
<p>Example of config file.</p>
<pre><code class="language-bash">input { stdin {} }

filter {
	mutate {
		add_field =&gt; { "greeting" =&gt; "Hello %{message}" }
	}
}

output { stdout {} }
</code></pre>
<p>This will take input from <code>STDIN</code> and output it to <code>STDOUT</code>, anything we type would be returned in a structured format with a <code>greeting</code> field.</p>
<h2 id="logstash-plugins"><a class="header" href="#logstash-plugins">Logstash Plugins</a></h2>
<p>It has more than 100 packages installed with logstash</p>
<p><code>/usr/share/logstash/bin/logstash-plugins list</code> for listing them</p>
<ul>
<li>
<p>Beats: Input plugin to work with <code>beats</code></p>
<pre><code class="language-bash">input { beats { port =&gt; 5044 } }
</code></pre>
</li>
<li>
<p>File:</p>
<ul>
<li>Get input from a file, or multiple, you can use wildcards</li>
</ul>
<pre><code class="language-bash">input { file { path=&gt; "/var/log/kern.log" } }
</code></pre>
</li>
<li>
<p>elasticsearch</p>
<ul>
<li>this is an <strong>output</strong> plugin, you can point to multiple servers</li>
</ul>
<pre><code class="language-bash">output { elasticsearch { host =&gt; ["localhost:9200"] } }
</code></pre>
</li>
</ul>
<h2 id="filters"><a class="header" href="#filters">Filters</a></h2>
<ul>
<li>
<p>Grok</p>
<ul>
<li>convert unstructured data to structured data</li>
<li>based on regex, but it has many abstractions in case you want to use them</li>
</ul>
<pre><code class="language-bash">filter {
	grok {
		match =&gt; {
			"message" =&gt; "%{IP:client} %{WORD:method} %{URIPATHPARAM}:request...."
		}
	}
}
</code></pre>
</li>
<li>
<p>Mutate</p>
<ul>
<li>let you transform the data</li>
</ul>
<pre><code class="language-bash">filter {
	grok {
		match =&gt; {
			"message" =&gt; "%{TIMESTAMP:t} new users: %{GREEDYDATA:users}"
			# 2024-01-23 new users: jose,pedro,maria
		}
	}

	mutate {
		split =&gt; {"users" =&gt; ","}
	}
}
</code></pre>
<p>In this example <em>grok</em> will get the time stamp of the message and will get all the string after <code>new users:</code> then we use <em>mutate</em> to split the users and have it stored as a list so when the data shows up in elasticsearch it looks like an array</p>
</li>
</ul>
<h2 id="grokconstructor"><a class="header" href="#grokconstructor">GrokConstructor</a></h2>
<p><a href="http://grokconstructor.appspot.com">grokconstructor.appspot.com</a> Helper for creating grok filters.</p>
<p>You can see also some <strong>grok patterns</strong> too.</p>
<p>Basically you can paste the logs there build your filter from there</p>
<p><img src="img/grok.png" alt="grok.png" /></p>
<h1 id="beats"><a class="header" href="#beats">Beats</a></h1>
<p>Why use beats? Logstash is overkill for a lot of things people use it for.</p>
<p>It uses JRuby (basically ruby that runs on the JVM), and by default it is
configured to set aside 1GiB of memory for the JVM. That is too much to just
send things to Elastic</p>
<p><strong>Beats</strong> (written in Go) is way more ü™Ω<strong>lightweight</strong>, it has been design to be. Becuase of this can be run everywhere.</p>
<p>There are several beats</p>
<ul>
<li>Heartbeat (Uptime)</li>
<li>Filebeat (Logs and text data)</li>
<li>Metricbeat (Metrics)</li>
<li>Packetbeat (Network data)</li>
<li>Winlogbeat (Windows events logs)</li>
<li>Auditbeat (audit logs and data)</li>
<li>Functionbeat (serverless data)</li>
</ul>
<aside>
üí° Note on Heartbeat (on opposed to other beats) run centrally and monitors
servers, instead of the other way around.
</aside>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
